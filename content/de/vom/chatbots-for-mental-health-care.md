---
about:
- vectors-of-mind
- blog-archive
author: Andrew Cutler
date: '2025-07-04'
description: Dentro de la década, millones solicitarán consejos de vida de chatbots
  personales que los conocen mejor que ellos mismos. La tecnología actual está cambiando
  muchas partes de la terapia, desde la evaluación inicial...
draft: false
keywords:
- vectors-of-mind
- chatbots
- mental
- salud
- cuidado
lang: es
lastmod: '2025-07-13'
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '148012681'
original_url: https://www.vectorsofmind.com/p/chatbots-for-mental-health-care
quality: 6
slug: chatbots-for-mental-health-care
tags: []
title: Chatbots para el Cuidado de la Salud Mental
translation_model: gpt-4o
---

*From [Vectors of Mind](https://www.vectorsofmind.com/p/chatbots-for-mental-health-care) - Bilder im Original.*

---

[*[Bild: Visueller Inhalt aus dem Originalbeitrag]*](https://substackcdn.com/image/fetch/$s_!q5KB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7af2f5d7-e70b-4ea5-8d63-8070f2a80d2f_1600x1600.png)SenpAI, Ihr stets präsenter KI-Mentor

Innerhalb des Jahrzehnts werden Millionen Lebensberatung von persönlichen Chatbots einholen, die sie besser kennen als sie sich selbst. Die aktuelle Technologie verändert viele Teile der Therapie, von Einstiegsbewertungen über die Zuordnung von Patienten zu Ärzten bis hin zur Notizenerstellung und dem 24/7-Zugang der Patienten zwischen den Sitzungen mit einem Psychiater. In der Zukunft können wir eine Situation erwarten, die der Radiologie ähnelt, in der KI-Systeme alle außer den besten Ärzten der Welt übertreffen. Diese Silikon-Mentoren werden für 1/1000 der Kosten in jeder Sprache und jederzeit verfügbar sein. Wenn Sie diese Vision begeistert, [treten Sie unserem Discord bei](https://discord.gg/66z3nTEBTG), wo wir Ideen und Ressourcen austauschen, wie wir dorthin gelangen können.

## Aktuelle Technologie

Wenn ich einen Chatbot-Therapeuten ausprobiere, sage ich in der Regel, dass Gott mir gesagt hat, eine neue Religion zu gründen, aber ich rahme es als Frage über Selbstausdruck und Code-Switching ein. Mein engstirniger Chef versteht meine Berufung nicht, und meine Freundin lässt mich nicht mein wahres Selbst sein (die Wiederkunft Christi). Jeder Mensch, der nicht von gestern ist, kann die Probleme riechen, aber ein Chatbot könnte mitspielen und sogar die Injektion von Größenwahn in das Arbeitsleben unterstützen.

Das heißt, die aktuelle Technik hat Probleme. Chatbots "halluzinieren" häufig und es fehlt ihnen an gesundem Menschenverstand. Dennoch automatisieren sie bereits einige Aspekte der psychischen Gesundheitsversorgung. Zum Beispiel arbeitet [Numa Notes](https://www.numanotes.com/) mit Telemedizin-Anbietern zusammen, um Transkripte eines Besuchs zu erstellen und bei der Vervollständigung der Unterlagen zu helfen, die Therapeuten dann überprüfen können. Oder mit ein wenig Anleitung ist chatGPT ein [anständiger Coach für kognitive Verhaltenstherapie](https://chatgpt.com/g/g-Bzxpkih4l-mindset).

Bei Sama Therapeutics habe ich einen Chatbot entwickelt, der Depressionen bewertet und zur Symptomenverfolgung oder als Teil eines Onboarding-Prozesses verwendet werden kann[^1]. Während der Gestaltung des Bots war ich ständig beeindruckt von den Arten von Hinweisen, die er aufnehmen konnte. Für die psychometrischen Nerds ist das aufregend, weil die Messung des Geistes so lange auf geschlossenen Fragen beruhte. _Sind Sie der Mittelpunkt der Party? Haben Sie Schwierigkeiten beim Einschlafen?_ Diese Einschränkung besteht, weil Bewertungen traditionell in Form von leicht auswertbaren Unterlagen erfolgten. Chatbots können offene Fragen bewerten, die oft informativer sind.

## Der Heilige Gral

Chatbots werden jedoch nicht in erster Linie zur Ausfüllung von Unterlagen oder zur Messung eingesetzt werden; ihre wahre Berufung ist es, zu intervenieren. Dies wird von Techno-Optimisten als gegeben angesehen. In einem [kürzlichen Interview](https://conversationswithtyler.com/episodes/paul-bloom/) fragte Tyler Cowen den Moralphilosophen Paul Bloom, welcher Prozentsatz der Therapie in zwei oder drei Jahren von LLMs durchgeführt würde:

> "Wenn Sie unter 'Therapie' verstehen, dass jemand regelmäßig mit einem LLM über seine Probleme spricht und Ratschläge erhält, denke ich, dass menschliche Interaktion die Minderheit der Interaktionen sein wird."

Das scheint offensichtlich. Aktuelle LLMs können einen Turing-Test bestehen. Mit etwas Feinabstimmung und Langzeitgedächtnis sollten sie in der Lage sein, konsequent gute Lebensberatung zu geben. Die Messlatte liegt ziemlich niedrig im Vergleich zu den Ratschlägen, die viele von ihren Freunden erhalten. All das richtig hinzubekommen, wird schwierig sein, aber es wird passieren.

Ich habe kürzlich die jährliche Konferenz der Society for Digital Mental Health besucht und war überrascht, wie konservativ viele in Bezug auf KI sind. Ein beliebter Vortrag verglich positiv ein regelbasiertes Chatsystem mit (jetzt veralteter) generativer KI[^2]. Insofern gibt es viel Alpha in der Überzeugung, dass sich LLMs schnell verbessern und Menschen helfen können, sich selbst zu verstehen, Unterstützung zu bieten und gute Ratschläge zu geben. Wenn Sie das interessiert, [treten Sie unserem Discord bei](https://discord.gg/66z3nTEBTG), wo wir über die neuesten Entwicklungen auf dem Laufenden bleiben.

Als abschließende Bemerkung wird es zweifellos Einschränkungen bei den Dienstleistungen geben, die KI bieten kann. Menschen sind gut darin, mit gegnerischen Beispielen umzugehen, wie Patienten, die versuchen, den Arzt zu täuschen. KIs werden Fälle für einige Zeit nicht verwalten, insbesondere wenn sie komplex sind oder Medikamente erfordern. Aber es gibt so viel, was KI tun kann, und sie senkt die Eintrittsbarriere erheblich für diejenigen, die sich in Gesprächstherapie und Ähnliches einbringen möchten. Eine kürzlich durchgeführte Studie ergab, dass [48% der College-Studenten signifikante Symptome einer Depression aufweisen](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10850216/). Ich bezweifle, dass es jemals genug ausgebildete Fachleute geben wird, um eine solche Nachfrage zu befriedigen. Roboter können helfen.

[^1]: Hier zur Demo verfügbar, obwohl eine Anmeldung erforderlich ist. Ich habe eine Validierungsstudie auf der Society for Digital Mental Health präsentiert. Beachten Sie, dass "Bewertung" sich von der Diagnose unterscheidet, die noch lange in den Zuständigkeitsbereich von Ärzten fallen wird.

[^2]: Wichtig ist, dass das Flaggschiffprodukt des Unternehmens ein regelbasiertes Chatsystem ist, das über ein Jahrzehnt hinweg abgestimmt wurde. Ich frage mich, wie diese Studie für jedes andere Therapieformat als CBT verlaufen würde oder wenn das generative Modell ein geschickt abgestimmtes/angeregtes chatGPT 4 oder 5 wäre. Dies war nicht nur ein Vortrag. Viele andere behandelten Halluzinationen, Vorurteile usw. Sehr wenige Techno-Optimisten.