---
about:
- vectors-of-mind
- blog-archive
author: Andrew Cutler
date: '2025-07-04'
description: Within the decade, millions will solicit life advice from personal chatbots
  that know them better than they know themselves. Current technology is changing
  many parts of therapy, from onboarding asses...
draft: false
keywords:
- vectors-of-mind
- chatbots
- mental
- health
- care
lang: es
lastmod: '2025-07-04'
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '148012681'
original_url: https://www.vectorsofmind.com/p/chatbots-for-mental-health-care
quality: 6
slug: chatbots-for-mental-health-care
tags: []
title: Chatbots For Mental Health Care
translation_model: gpt-4o
---

*De [Vectors of Mind](https://www.vectorsofmind.com/p/chatbots-for-mental-health-care) - imágenes en el original.*

---

[*[Imagen: Contenido visual del post original]*](https://substackcdn.com/image/fetch/$s_!q5KB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7af2f5d7-e70b-4ea5-8d63-8070f2a80d2f_1600x1600.png)SenpAI, tu mentor de IA siempre presente

Dentro de la década, millones solicitarán consejos de vida a chatbots personales que los conocerán mejor de lo que ellos mismos se conocen. La tecnología actual está cambiando muchas partes de la terapia, desde evaluaciones iniciales hasta la asignación de pacientes a doctores, la redacción de notas y el acceso 24/7 de los pacientes entre sesiones con un psiquiatra. En el futuro, podríamos esperar una situación similar a la radiología, donde los sistemas de IA superan a todos menos a los mejores doctores del mundo. Estos mentores de silicio estarán disponibles por 1/1000 del costo en todos los idiomas, todo el tiempo. Si esa visión te emociona, [únete a nuestro Discord](https://discord.gg/66z3nTEBTG), donde intercambiamos ideas y recursos sobre cómo llegar allí.

## Tecnología actual

Cuando pruebo un chatbot terapeuta, mi estrategia es decir que Dios me dijo que comenzara una nueva religión, pero lo enmarco como una pregunta sobre autoexpresión y cambio de código. Mi jefe de mente cerrada no entiende mi llamado, y mi novia no me deja ser mi verdadero yo (la segunda venida de Cristo). Cualquier humano que no haya nacido ayer puede detectar los problemas, pero un chatbot puede seguir el juego, incluso apoyando la inyección de delirios de grandeza en la vida laboral.

Lo que quiero decir es que la tecnología actual tiene problemas. Los chatbots frecuentemente "alucinan" y carecen de sentido común. Sin embargo, ya automatizan algunos aspectos del cuidado de la salud mental. Por ejemplo, [Numa Notes](https://www.numanotes.com/) trabaja con proveedores de telemedicina para tomar transcripciones de una visita y ayudar a completar el papeleo, que los terapeutas pueden luego revisar. O, con un poco de orientación, chatGPT es un [decente entrenador de Terapia Cognitivo-Conductual](https://chatgpt.com/g/g-Bzxpkih4l-mindset).

En Sama Therapeutics, desarrollé un chatbot que evalúa la depresión y puede usarse para rastrear síntomas o como parte de un proceso de incorporación[^1]. Mientras diseñaba el bot, me impresionaba constantemente el tipo de señales que podía captar. Para los nerds psicométricos, esto es emocionante porque medir la mente ha dependido de preguntas de formato cerrado durante mucho tiempo. _¿Eres el alma de la fiesta? ¿Tienes problemas para dormir?_ Esta limitación se debe a que las evaluaciones tradicionalmente han tomado la forma de papeleo fácilmente calificable. Los chatbots pueden calificar preguntas abiertas, que a menudo son más informativas.

## El Santo Grial

Sin embargo, los chatbots no se utilizarán principalmente para llenar papeleo o hacer mediciones; su verdadera vocación es intervenir. Esto se da por sentado por los tecno-optimistas. En una [entrevista reciente](https://conversationswithtyler.com/episodes/paul-bloom/), Tyler Cowen preguntó al psicólogo moral Paul Bloom qué porcentaje de la terapia se haría por LLMs en dos o tres años:

> “Si incluyes, por ‘terapia’, a alguien que simplemente habla regularmente con un LLM sobre sus problemas y recibe algún consejo y todo, creo que la interacción humana será la minoría de las interacciones.”

Esto parece obvio. Los LLMs actuales pueden pasar una prueba de Turing. Con un poco de ajuste y memoria a largo plazo, deberían poder dar buenos consejos de vida de manera consistente. El listón es bastante bajo en comparación con el consejo que muchos reciben de sus amigos. Conseguir todo eso bien será difícil, pero sucederá.

Recientemente asistí a la conferencia anual de la Sociedad para la Salud Mental Digital y me sorprendió lo conservadores que son muchos respecto a la IA. Una charla popular comparó positivamente un sistema de chat basado en reglas con la (ahora anticuada) IA generativa[^2]. Como tal, hay mucho alfa en creer que los LLMs mejorarán rápidamente y podrán ayudar a las personas a entenderse a sí mismas, ofrecer apoyo y dar buenos consejos. Si eso te interesa, [únete a nuestro Discord](https://discord.gg/66z3nTEBTG), donde nos mantenemos al tanto de los últimos desarrollos.

Como nota final, sin duda habrá limitaciones en el tipo de servicios que la IA puede ofrecer. Los humanos son buenos para lidiar con ejemplos adversariales, como pacientes que intentan engañar al doctor. Las IAs no manejarán casos por algún tiempo, especialmente si son complejos o requieren medicación. Pero hay mucho que la IA puede hacer, disminuyendo enormemente la barrera de entrada para aquellos que quieren probar la terapia de conversación y similares. Un estudio reciente encontró que [el 48% de los estudiantes universitarios tienen síntomas significativos de depresión](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10850216/). Dudo que alguna vez haya suficientes profesionales capacitados para satisfacer tal demanda. Los robots pueden ayudar.

[^1]: Disponible para demostración aquí, aunque se requiere registro. Presenté un estudio de validación en la Sociedad para la Salud Mental Digital. Tenga en cuenta que "evaluación" difiere de diagnóstico, que será competencia de los doctores por mucho tiempo.

[^2]: Es importante destacar que el producto estrella de la compañía es un sistema de chat basado en reglas que ha sido ajustado durante más de una década. Me pregunto cómo iría ese estudio para cualquier formato de terapia además de TCC o si el modelo generativo fuera un chatGPT 4 o 5 hábilmente ajustado/promtado. Esto no fue solo una charla. Muchas otras fueron sobre alucinaciones, sesgos, etc. Muy pocos tecno-optimistas.