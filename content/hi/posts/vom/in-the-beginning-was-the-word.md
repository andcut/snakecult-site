---
about:
- vectors-of-mind
- blog-archive
author: Andrew Cutler
date: '2025-07-04'
description: “In the beginning was the Word, and the Word was with Psychology, and
  the Word was Psychology” ~New Vector Translation
draft: false
keywords:
- vectors-of-mind
- beginning
- word
lang: hi
lastmod: '2025-07-09'
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '51210419'
original_url: https://www.vectorsofmind.com/p/in-the-beginning-was-the-word
quality: 6
slug: in-the-beginning-was-the-word
tags: []
title: शुरुआत में शब्द था
translation_model: gpt-4o
---

*From [Vectors of Mind](https://www.vectorsofmind.com/p/in-the-beginning-was-the-word) - images at original.*

---

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!5qwE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9f7c2505-9587-4daa-aac2-648b8bf16efb_1200x544.png)

_"शुरुआत में शब्द था, और शब्द मनोविज्ञान के साथ था, और शब्द मनोविज्ञान था" ~न्यू वेक्टर अनुवाद_

सभी व्यक्तित्व निर्माण पहले शब्दों द्वारा वर्णित होते हैं। फ्रायड के कोकीन-प्रेरित मॉडलों से लेकर स्थिर बिग फाइव तक, वे सभी एक समय पर शब्द होते हैं। शैक्षणिक मनोविज्ञान का अधिकांश हिस्सा निर्माणों की तुलना करने में लगा रहता है। ऐसा करने के लिए, उन्हें एक आधार साझा करना चाहिए, आमतौर पर विषयों का एक सेट। विषयों को एक उपकरण (आमतौर पर एक सर्वेक्षण) दिया जाता है जो यह अनुमान लगाता है कि वे निर्माण स्थान में कहाँ रहते हैं। विषय प्रतिक्रियाओं के सह-परिवर्तन के आधार पर, निर्माणों के बारे में सामान्य दावे किए जाते हैं। इस पोस्ट में हम एक और तरीका खोजते हैं। एनएलपी में प्रगति निर्माणों की उनके प्राकृतिक निवास स्थान: भाषा में मात्रात्मक तुलना की अनुमति देती है।

### रोडमैप

[पिछली पोस्ट](https://vectors.substack.com/p/the-big-five-are-word-vectors?s=w) में मैंने तर्क दिया कि बिग फाइव शब्द वेक्टर हैं। यह पोस्ट स्वतंत्र स्केल के बारे में भी यही दावा करती है, जो तब विषयों को शामिल किए बिना निर्माणों की तुलना करने की अनुमति देती है। इसे प्रदर्शित करने के लिए, एक व्यापक व्यक्तित्व मॉडल पेश किया गया है, साथ ही शब्द स्थान में निर्माणों का प्रतिनिधित्व करने की एक विधि भी पेश की गई है। रूपरेखा इस प्रकार है:

1. विषय बनाम शब्द स्थान में निर्माणों की तुलना करें

2. विषय स्थान की समस्याएँ

3. विषयों का उपयोग करके बिग फाइव से संबंध और पारस्परिक परोपकारिता को जोड़ें

4. शब्द स्थान में वही तुलना

1. एनएलपी का उपयोग करके पहचाने गए (अस्थायी) पांच कारक मॉडल को पेश करें

2. उस स्थान में परोपकारिता शब्दों को प्रक्षिप्त करें

3. कोड [यहाँ](https://colab.research.google.com/drive/13DA2IKQ9zRimGedww_09iGT6ehuYriVz?usp=sharing) उपलब्ध है।

5. चर्चा, सीमाएँ, भविष्य का कार्य

### **एक कठिन मार्ग**

परोपकारिता की बिग फाइव से तुलना करने के लिए, संकेत को कई रूपांतरणों से गुजरना होगा: परोपकारिता (आदर्श) → शब्दों द्वारा वर्णित → इस निर्माण का अनुमान लगाने के लिए सर्वेक्षण विकसित किया गया (और उम्मीद है कि मान्य किया गया) → विषय को प्रशासित किया गया जो इन शब्दों की व्याख्या करता है और अपनी आत्मा की खोज करता है → विषय परोपकारिता स्कोर → **विषय स्थान में सहसंबंध** ← विषय बिग फाइव इन्वेंटरी (बीएफआई) स्कोर ← विषय बीएफआई आइटम की व्याख्या करता है और आत्मा की खोज करता है ← लगभग मापने के लिए बीएफआई विकसित करें ← गुणात्मक विवरण द्वारा परिभाषित/संचारित निर्माण ← बिग फाइव (शब्द लोडिंग द्वारा परिभाषित)। तब परोपकारिता और बिग फाइव के दो आदर्शों के बारे में दावे किए जाते हैं।

### **सीधा और संकीर्ण**

विषयों के बजाय साझा आधार के रूप में शब्द वेक्टर का उपयोग क्यों नहीं किया जाता? मार्ग कहीं अधिक प्रत्यक्ष है: परोपकारिता (आदर्श) → शब्दों द्वारा वर्णित → शब्द स्थान में वेक्टराइज्ड → **शब्द स्थान में तुलना** ← बिग फाइव, जो पहले से ही शब्द स्थान में मौजूद हैं, जैसा कि [पिछली पोस्ट](https://vectors.substack.com/p/the-big-five-are-word-vectors?s=w) में चर्चा की गई है। जो लोग स्कोर रख रहे हैं उनके लिए यह 4 बनाम 10 रूपांतरण है। (यह गोल्फ की तरह स्कोर किया जाता है।)

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!tbb9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb8b6c50-e94e-4462-8772-78359189f70e_1600x1305.png)मनोविज्ञान के क्षेत्र में सांख्यिकीय वास्तविकताएँ आ रही हैं। यह कुछ कठिन वर्षों का समय रहा है।

### **ताल द रिवेलेटर**

मौखिक निर्माणों के बारे में दावे करने के लिए विषयों का उपयोग करने की कठिनाई कोई रहस्य नहीं है।

> _"मनोविज्ञान में अधिकांश सिद्धांत और परिकल्पनाएँ मौखिक प्रकृति की होती हैं, फिर भी उनका मूल्यांकन अत्यधिक रूप से अनुमानात्मक सांख्यिकीय प्रक्रियाओं पर निर्भर करता है। गुणात्मक से मात्रात्मक विश्लेषण में परिवर्तन की वैधता इस बात पर निर्भर करती है कि परिकल्पना की मौखिक और सांख्यिकीय अभिव्यक्तियाँ निकटता से संरेखित हैं - अर्थात, दोनों को लगभग एक ही सेट के काल्पनिक अवलोकनों का संदर्भ देना चाहिए। यहाँ, मैं तर्क देता हूँ कि मनोविज्ञान में सांख्यिकीय अनुमान के कई अनुप्रयोग इस बुनियादी शर्त को पूरा करने में विफल रहते हैं।" ~ताल यारकोनी,_ [सामान्यीकरण संकट](https://psyarxiv.com/jqw35/)

यहाँ वैधता का अर्थ है एक स्कोर जो उस निर्माण को पकड़ता है जिसे मापने का इरादा है। तर्कों और उदाहरणों को पूरी तरह से पढ़ना सार्थक है। लेकिन हमारे लिए घर ले जाने वाली बात यह है कि इन वास्तविकताओं को देखते हुए क्या किया जा सकता है। वह सुझाव देते हैं:

1. कुछ और करें (अन्य क्षेत्रों में प्रवेश करें)।

2. गुणात्मक अनुसंधान को अपनाएँ

3. बेहतर मानकों को अपनाएँ (जिसमें 7 सुझाव शामिल हैं)।

> _"कोई भी हमेशा यह दिखावा करने के लिए स्वतंत्र है कि अत्यधिक संकीर्ण सांख्यिकीय संचालन से प्राप्त छोटे पी-मूल्य जटिल मनोवैज्ञानिक निर्माणों के बारे में व्यापक मौखिक अनुमान लगाने के लिए एक पर्याप्त आधार प्रदान कर सकते हैं। लेकिन कोई और नहीं - न तो आपके सहकर्मी, न आपके फंडर्स, न जनता, और निश्चित रूप से न ही दीर्घकालिक वैज्ञानिक रिकॉर्ड - इस दिखावे का सम्मान करने के लिए बाध्य है।"_

यहां तक कि अगर मनोविज्ञान में अनुसंधान के बारे में आपका दृष्टिकोण इतना धुंधला नहीं है, तो निश्चित रूप से पाठकों को उन पत्रों से जलाया गया है जो दावे करते हैं लेकिन प्रयोगों को नियोजित करते हैं जो केवल ढीले ढंग से संबंधित हैं। सभी उपलब्ध समाधान दर्दनाक हैं। क्षेत्र को एक संकीर्ण दृष्टिकोण अपनाना पड़ सकता है और बड़े प्रश्नों को इतिहास, साहित्य और रैखिक बीजगणित का अध्ययन करने वालों के लिए छोड़ देना पड़ सकता है। मैं आगे बढ़ने का एक और तरीका प्रस्तावित करता हूँ।

### **शब्द स्थान में परिवर्तित करें**। 4. साझा आधार के रूप में शब्द वेक्टर का उपयोग करें

निर्माण शब्द स्थान में एक साथ रहते हैं, और फिर भी जब तुलना की जाती है तो हम उन्हें विषय स्थान में खींचते हैं। यह एक विशाल, हानिपूर्ण, परेशानी है। क्या होगा अगर वे सुरक्षित रूप से शब्द स्थान में रह सकते हैं? प्राकृतिक भाषा प्रसंस्करण का दिखावा यह है कि शब्द निरंतर स्थान में वेक्टर होते हैं। इन वेक्टरों का विश्लेषण करना पर्याप्त रूप से काम करता है ताकि यह [लोड](https://youtu.be/SGzMElJ11Cc?t=6667) [बियरिंग](https://www.amazon.jobs/en/search?base_query=natural+language+processing&loc_query=&latitude=&longitude=&loc_group_id=&invalid_location=false&country=&city=&region=&county=) [प्रक्रिया](https://blog.google/products/search/search-language-understanding-bert/) ट्रिलियन डॉलर उद्योगों में हो, और वर्तमान में इसे मनोविज्ञान में ([पुनः](https://vectors.substack.com/p/the-big-five-are-word-vectors?s=w))परिचित कराया जा रहा है।

### **जो उपदेश देते हो उसका अभ्यास करो**

यहाँ हम विषय स्थान में किए गए एक पारंपरिक अध्ययन को देखेंगे और फिर इसे शब्द स्थान में स्थानांतरित करके सुधारने का प्रयास करेंगे। एक पुआल आदमी के खिलाफ बचाव करते हुए, वस्तु [किन अल्ट्रुइज़्म, रेसिप्रोकल अल्ट्रुइज़्म, और बिग फाइव पर्सनैलिटी फैक्टर्स](https://www.sciencedirect.com/science/article/abs/pii/S1090513898000099?casa_token=05bTreOjGKUAAAAA:nLHTWhK3z45xUbN5nTVd7a3-Qaz9No22rQtVY6vpUjYpeZ1bkPy-cBig9UgRbn-GnqJScTCPpSY) है जिसे सैकड़ों बार उद्धृत किया गया है और जिसके पहले लेखक का एच-इंडेक्स 70 है।

विषयों को तीन उपकरणों का उपयोग करके मापा जाता है: बिग फाइव (विशेषणों के सर्वेक्षण के माध्यम से), सहानुभूति/संलग्नता और क्षमा/गैर-प्रतिशोध (वाक्यांशों का सर्वेक्षण), और एक धन-विभाजन खेल में परोपकारिता। क्योंकि लेखक यह परिकल्पना करते हैं कि सहमति और भावनात्मक स्थिरता (उर्फ न्यूरोटिसिज्म) के बीच का अंतःस्थलीय स्थान दो परोपकारिताओं को अलग करता है, उस क्षेत्र को बेहतर मापने के लिए कुछ शब्द जोड़े जाते हैं। इसी तरह, सहानुभूति/संलग्नता और क्षमा/गैर-प्रतिशोध को मापने के लिए एक नया प्रश्नावली डिज़ाइन किया गया है, जिन्हें क्रमशः किन बनाम पारस्परिक परोपकारिता से संबंधित के रूप में सिद्धांतित किया गया है। इस प्रकार के अध्ययन के लिए ऊपर और परे, एक खेल का उपयोग परोपकारिता को मापने के लिए किया जाता है।

> _"परोपकारिता को मापने के लिए उपयोग किए गए धन आवंटन कार्य के संस्करण में, दूसरे व्यक्ति को एक करीबी मित्र के रूप में वर्णित किया गया था - कोई ऐसा व्यक्ति जिसके साथ प्रतिभागी का लंबे समय से मित्रता का इतिहास था और जिसके साथ प्रतिभागी का बहुत कुछ समान था। हमें उम्मीद थी कि दोस्ती को पुरानी और दोस्त को प्रतिभागी के समान बताया जाएगा, दोस्ती उस रिश्ते के समान होगी जो किसी रिश्तेदार के साथ होती है। हमने परोपकारिता के संभावित वस्तु के रूप में किसी रिश्तेदार का उपयोग नहीं करने का कारण यह था कि शामिल विशेष रिश्तेदार के कारण प्रतिक्रियाओं में भिन्नता को पेश करने से बचा जा सके; उदाहरण के लिए, कई लोग एक भाई की तुलना में दूसरे भाई के प्रति अधिक परोपकारी व्यवहार करने के लिए अधिक इच्छुक हो सकते हैं।"_

दूसरे शब्दों में, वास्तविक दुनिया की भावनाओं के साथ डेटा को दूषित न करने के लिए, पारस्परिक परोपकारिता को मापा जाता है।

> _"परोपकारिता को मापने के लिए उपयोग किए गए धन आवंटन कार्य के संस्करण में, दूसरे व्यक्ति को एक गैर-सहयोगी के रूप में वर्णित किया गया था - कोई ऐसा व्यक्ति जिसने प्रतिभागी के प्रति असभ्य, बुरा और असंगत व्यवहार किया था।"_

और पारस्परिक परोपकारिता को मापने के लिए वे मापते हैं ... गैर-पारस्परिक परोपकारिता? स्वाभाविक रूप से सहसंबंध होते हैं और लेखक निष्कर्ष निकालते हैं:

> _"इस अध्ययन के परिणाम इस सुझाव का समर्थन करते हैं कि सहानुभूति और संलग्नता से संबंधित व्यक्तित्व लक्षण मुख्य रूप से रिश्तेदारों की ओर निर्देशित परोपकारिता (यानी, किन परोपकारिता) को सुविधाजनक बनाते हैं, और क्षमा और गैर-प्रतिशोध से संबंधित व्यक्तित्व लक्षण मुख्य रूप से गैर-रिश्तेदारों की ओर निर्देशित परोपकारिता (यानी, पारस्परिक परोपकारिता) को सुविधाजनक बनाते हैं।"_

लेकिन अगर पारस्परिक परोपकारिता को कभी मापा नहीं गया, तो परिणाम उस दावे का समर्थन कैसे कर सकते हैं? मनोविज्ञान पत्रों में सांख्यिकी, जैसा कि ताल बताते हैं, अक्सर एक अलंकारिक अलंकरण होते हैं। लेकिन हमें साथ खेलने की ज़रूरत नहीं है! आइए देखें कि शब्द स्थान क्या कहता है।

### **दूध और शहद की भूमि (शब्द स्थान में आपका स्वागत है)**

पारंपरिक अध्ययनों में, व्यक्तित्व स्थान पर विषयों को मैप करने की लागत के कारण, कुछ व्यक्तित्व क्षेत्रों में ही संकल्पना उच्च हो सकती है। यही कारण है कि लेखक सहानुभूति और गैर-प्रतिशोध और सहमति और भावनात्मक स्थिरता के बीच के स्थान की जांच करते हैं। उन सभी अक्षों [नियमित बिग फाइव स्थान में मौजूद हैं](https://psyarxiv.com/vebtm/), लेकिन काफी बारीकी से मापे जाते हैं। शब्द स्थान में हम परोपकारिता की तुलना पूर्ण बिग फाइव से कर सकते हैं, उनकी सभी उच्च-रिज़ॉल्यूशन महिमा में। मेरे गिटहब पर 2819 शब्द वेक्टर हैं जिन्हें पांच पीसी तक घटाया गया है। हम सुविधा के लिए उनका उपयोग कर सकते हैं। पहला कार्य यह है कि प्रत्येक परोपकारिता का वर्णन करने वाले शब्द सेट का चयन किया जाए। किन शब्दों के लिए मैंने उन शब्दों को चुना जो पारिवारिक भूमिकाओं को दर्शाते हैं: _भाईचारा, बहनचारा, मातृत्व, मातृ, पितृत्व, दादी, दादा, पत्नी, मातृ, पितृ।_ पारस्परिक परोपकारिता के लिए, मैं ट्रिवर्स की परिभाषा का पालन करता हूँ।

> _"मानव पारस्परिक परोपकारिता के संबंध में, यह दिखाया गया है कि इस परोपकारिता को नियंत्रित करने वाली मनोवैज्ञानिक प्रणाली के विवरण को मॉडल द्वारा समझाया जा सकता है। विशेष रूप से, **मित्रता, नापसंद, नैतिक आक्रामकता, आभार, सहानुभूति, विश्वास, संदेह, विश्वासयोग्यता, अपराध के पहलू, और कुछ प्रकार की बेईमानी और पाखंड** को परोपकारिता प्रणाली को नियंत्रित करने के लिए महत्वपूर्ण अनुकूलन के रूप में समझाया जा सकता है। प्रत्येक मानव को **परोपकारी और धोखेबाज प्रवृत्तियों** के रूप में देखा जाता है, जिनकी अभिव्यक्ति विकासात्मक चर के प्रति संवेदनशील होती है जिन्हें स्थानीय सामाजिक और पारिस्थितिक पर्यावरण के लिए उपयुक्त संतुलन पर प्रवृत्तियों को सेट करने के लिए चुना गया था।" _[पारस्परिक परोपकारिता का विकास](https://www.journals.uchicago.edu/doi/abs/10.1086/406755), रॉबर्ट ट्रिवर्स (बोल्डिंग जोड़ा गया)

इसे ध्यान में रखते हुए, मैंने चुना: _विवेकशील, क्षमाशील नहीं, प्रतिशोधी, वफादार, पड़ोसी, सहयोगी, विश्वासयोग्य,_ और _निष्पक्ष।_ यह सहयोग की ओर झुकाव पर लगभग समान है लेकिन जब चीजें गलत होती हैं तो नैतिक आक्रामकता के साथ पालन करता है। इसके अतिरिक्त, यह इस परोपकारिता को धोखाधड़ी के विरोधी के रूप में पकड़ने की कोशिश करता है (उदा. _निष्पक्ष_, _विश्वासयोग्य_)।

(विश्वास के विकास की उत्कृष्ट व्याख्या के लिए, [यह](https://ncase.me/trust/) इंटरैक्टिव डेमो देखें।)

#### क्या मैं आपको अज्ञात फाइव फैक्टर मॉडल से परिचित करा सकता हूँ?

सैद्धांतिक रूप से, हम सर्वेक्षणों के माध्यम से उत्पादित बिग फाइव शब्द लोडिंग का उपयोग कर सकते हैं, लेकिन इनमें से अधिकांश शब्द इतने दुर्लभ हैं कि शामिल नहीं किए गए हैं। यह सबसे अच्छा है क्योंकि मनोविज्ञान के छात्रों के बीच आत्म-रिपोर्ट द्वारा _दादी_ का अच्छा अनुमान नहीं मिलेगा। इस प्रकार, भाषा मॉडल रोबर्टा का उपयोग करके गणना किए गए शब्द वेक्टर। व्यक्तित्व शब्दों की एक बड़ी और [अच्छी तरह से विशेषता](https://openpsychologydata.metajnl.com/articles/10.5334/jopd.57/) सूची से व्युत्पन्न, परिणामी पांच कारक संक्षेप में हैं:

1. संबद्धता (या समाजीकरण)। आप इस व्यक्ति को अपनी टीम में कितना चाहते हैं? सहमति के समान लेकिन दरवाजे की चटाई होने से बचता है। उदाहरण के लिए, _गुल्लिबल_ संबद्धता पर तटस्थ रूप से लोड होता है लेकिन सहमति पर सकारात्मक रूप से।

2. गतिशीलता। काफी हद तक बहिर्मुखता से मेल खाता है, लेकिन अधिक साहसिक भावना के बारे में है, और आत्मविश्वास के बारे में कम।

3. आदेश। एक धार के साथ विवेकशीलता। अपने लक्ष्यों को प्राप्त करने की क्षमता। _सटीक_ बनाम _मुलायम_।

4. भावनात्मक लगाव। जबकि न्यूरोटिसिज्म अस्थिरता से संबंधित है, यह लगाव के बारे में है; दोनों _देखभाल_ और _द्वेषपूर्ण_ अत्यधिक लोड होते हैं।

5. पारलौकिकता। इस कारक की विशेषता _अद्वितीय, जटिल, तारा-पार, विकलांग, रहस्यमय, दिल टूटने वाला, अन्य-विश्व_ बनाम _अदर्शनशील, फैंसी-फ्री, जिद्दी, अशिष्ट, भौतिकवादी, आत्म-केंद्रित, ग्लिब_ है। इसमें स्वयं और सांसारिक से परे देखना शामिल है। वह प्रक्रिया, जाहिरा तौर पर, दर्द में लिपटी हुई है। वास्तव में, "परेशान" पारलौकिकता पर भावनात्मक लगाव (न्यूरोटिसिज्म से संबंधित कारक) की तुलना में अधिक लोड होता है।

पहले तीन कारकों के नाम डे राड के पैन सांस्कृतिक [कार्य](https://journals.sagepub.com/doi/10.1002/per.1953) से लिए गए हैं क्योंकि, गुणात्मक रूप से, मेल बिग फाइव की तुलना में अधिक निकट है। प्रत्येक कारक अपने स्वयं के पोस्ट का हकदार है। (औद्योगिक मनोविज्ञान में उन लोगों के लिए, मुझे संदेह है कि आदेश विवेकशीलता की तुलना में व्यावसायिक सफलता के साथ अधिक सहसंबद्ध है क्योंकि यह समय पर दिखाने की तुलना में अधिक गणना करने वाला है।) लेकिन मॉडल प्रस्तावित करना मेरा मजबूत पक्ष नहीं है, और बेहतर भाषा अध्ययन आ रहे हैं जो अलग संरचना दे सकते हैं। फिलहाल ये कारक पर्याप्त हैं। यहाँ उनका बिग फाइव के साथ सहसंबंध है:

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!Sxlw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F63c86f00-e0cc-4854-bd8a-e6ba3fc55449_366x374.png)

#### परिणाम

परोपकारिता शब्द लोडिंग पहले चार कारकों पर (इस अध्ययन में पारलौकिकता महत्वपूर्ण नहीं है):

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!Q5sr!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4efdfb85-197d-4d57-8a8b-3675eaf2b162_955x735.png)मजबूत पारिवारिक संबंध रखना सामाजिक है (उच्च संबद्धता), यदि थोड़ा उबाऊ (तटस्थ से निम्न गतिशीलता)। सभी शब्द एक समान स्थान पर मैप होते हैं।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!f7oe!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb08b529e-7443-4f5b-af1e-ce080e36a4b7_961x735.png)पारिवारिक शब्द भावनात्मक लगाव पर दृढ़ता से लोड होते हैं। ध्यान दें कि माता-पिता और दादा-दादी के रिश्ते काफी लिंग आधारित होते हैं। ट्रिवर्स के [माता-पिता निवेश सिद्धांत](http://joelvelasco.net/teaching/3330/trivers72-parentalinvestment.pdf) की भविष्यवाणी के अनुसार, पुरुष कम जुड़े हुए हैं, और [सांख्यिकी](https://www.pewresearch.org/social-trends/2013/07/02/the-rise-of-single-fathers/) इसे साबित करते हैं। हालांकि भाई और बहन समान रूप से जुड़े हुए हैं, और माता-पिता की तुलना में कम हद तक। सोचने की बात है, _पत्नी_ को रक्त संबंधियों के बारे में परोपकारिता में शामिल नहीं किया जाना चाहिए था। [डे टाइम टॉक शो](https://www.youtube.com/watch?v=jXZB0FeTyE8) के साथ सहमति में, यह मातृत्व या दादी की तुलना में लगाव पर कम लोड होता है।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!FYnd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa40e5562-577f-4b55-bd16-d34ccec1c388_955x735.png)पारस्परिक शब्द आदर्श टिट फॉर टैट व्यवहार को पकड़ने की कोशिश करते हैं जब एक साथी सहयोग कर रहा हो या धोखा दे रहा हो। इस प्रकार, ये शब्द कहीं अधिक फैले हुए हैं, हालांकि फिर भी ज्यादातर सकारात्मक हैं। यहां तक कि 'विवेकशील' भी थोड़ा सकारात्मक है, जिसका अर्थ है कि मुझे नहीं लगता कि शब्द को 'नस्लीय भेदभावपूर्ण' के रूप में कोड किया जा रहा है - कभी-कभी ये भाषाएं ध्वन्यात्मक समानता के साथ भ्रमित हो जाती हैं (उदा. सनकी और जातीयकेंद्रित)।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!lGox!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6eb4b7d2-4728-4f66-83ce-cd95e2346144_961x735.png)सहयोग और पड़ोसपन का थोड़ा सा मतलब है कि किसी के अपने लक्ष्य पीछे की सीट ले रहे हैं। क्षमाशील नहीं और विवेकशील उन लोगों के लिए हैं जो व्यवसाय का मतलब रखते हैं।

परोपकारिताओं की तुलना करने के लिए, हम चाहेंगे कि इन शब्द सेटों में से प्रत्येक को केवल एक वेक्टर तक घटा दिया जाए। (इस बात पर बहस की गुंजाइश है कि क्या यह भी समझ में आता है क्योंकि पारस्परिक - और कुछ हद तक किन - विभिन्न परिदृश्यों के लिए अलग-अलग प्रतिक्रियाओं की आवश्यकता होती है।) सस्ता और गंदा समाधान प्रत्येक निर्माण को [शब्दों का बैग](https://en.wikipedia.org/wiki/Bag-of-words_model) मानना और औसत लेना है। औसत लोडिंग हैं:

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!TMN7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3aaf685-9bb3-4dbf-974f-0ab994f40a88_356x238.png)ये सभी 2819 शब्दों के खिलाफ जेड स्कोर किए गए हैं। औसतन, किन शब्द संबद्धता और भावनात्मक लगाव पर 1-1.5 एसडी बाहर हैं।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!mDHG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fba83d4f1-2f47-42e8-a158-368c7681a2db_356x238.png)पारस्परिक परोपकारिता में भी आदेश शामिल है, अपने लक्ष्यों को पूरा करना।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!48eW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd912d107-48f4-4d5e-bb23-fe24dd932b78_356x238.png)अंतर: किन माइनस पारस्परिक लोडिंग। आदेश द्वारा प्रभुत्व।

### **चर्चा**

मुझे नहीं लगता कि विषय स्थान में पेपर में किन या पारस्परिक परोपकारिता का एक वैध उपाय शामिल है और इस प्रकार यह इस बात की हमारी समझ में नहीं जोड़ता है कि यह व्यक्तित्व से कैसे संबंधित है। यह एक आश्चर्यजनक रूप से सामान्य विफलता मोड है। शब्द स्थान अमान्य तुलनाओं के खिलाफ कुछ बीमा प्रदान करता है। हमारे पास इस बात की बेहतर अंतर्दृष्टि है कि शब्द स्थान में एक शब्द कहाँ होना चाहिए, बजाय इसके कि विषय 112 को सर्वेक्षण का उत्तर कैसे देना चाहिए। त्रुटियों को देखना आसान है।

बायेसियन दृष्टिकोण से, विषय बनाम शब्द स्थान में कुछ अलग हो रहा है। विषयों को शामिल करने वाले प्रयोग तालिका में नई जानकारी लाने की कोशिश करते हैं। आशा है कि यह पाठकों के विश्व दृष्टिकोण को अपडेट करेगा। लेकिन शोधकर्ताओं (और आम लोग) के पास सामाजिक अनुभव और मनोवैज्ञानिक प्रक्रियाओं की अधिक तीव्र धारणा होती है, जो सर्वेक्षण द्वारा प्रदान की गई स्नैपशॉट की तुलना में होती है। सुई को ज्यादा हिलाना मुश्किल है। शब्द स्थान हमारे पूर्वाग्रहों को देखने के समान है, न कि नए ज्ञान का उत्पादन करने के लिए। यह दृष्टिकोण मूल्यवान है क्योंकि भाषा वह जगह है जहाँ रबर सड़क से मिलता है, ऐसा कहने के लिए। जैसा कि जेएल ऑस्टिन ने कहा:

> _"हमारे सामान्य शब्दों का भंडार उन सभी भेदों को समाहित करता है जिन्हें पुरुषों ने खींचने लायक पाया है, और उन कनेक्शनों को चिह्नित करने लायक पाया है, जो कई पीढ़ियों के जीवनकाल में हैं: ये निश्चित रूप से अधिक संख्या में, अधिक ध्वनि वाले होने की संभावना है, क्योंकि उन्होंने फिटनेस के दीर्घकालिक परीक्षण का सामना किया है, और अधिक सूक्ष्म, कम से कम सभी सामान्य और उचित व्यावहारिक मामलों में, उन सभी की तुलना में जो आप या मैं दोपहर में अपनी कुर्सी पर सोचने की संभावना रखते हैं - सबसे पसंदीदा वैकल्पिक विधि।" [एक बहाने के लिए अपील](https://sites.ualberta.ca/~francisp/NewPhil448/AustinPlea56.pdf)_

शब्द स्थान में विश्लेषण तुलनात्मक रूप से सीधा है। सहसंबंधों और पी-मूल्यों की तालिकाओं के बजाय, शब्दों को बस रुचि के अक्षों पर प्लॉट किया जाता है और दृश्य निर्णय लिए जाते हैं। किन परोपकारिता शब्द संबद्धता और भावनात्मक लगाव पर कसकर समूह बनाते हैं, दोमात्र कारक जिनमें महत्वपूर्ण लोडिंग होती है। पिता, लेकिन भाई नहीं, अपनी महिला समकक्षों की तुलना में कम जुड़े हुए हैं, ट्रिवर्स के माता-पिता निवेश सिद्धांत के अनुरूप। भाइयों और बहनों के पास अपने भाई-बहनों की देखभाल करने का उतना ही कारण है। हालांकि, माताओं की तुलना में पिता के पास कम कारण होता है। शुक्राणु सस्ते हैं। अंडे और गर्भावस्था महंगे हैं।

पारस्परिक शब्द अधिक फैले हुए हैं, जो विभिन्न परिदृश्यों का जवाब देने के लिए आदर्श लक्षणों को दर्शाते हैं: साथी सहयोग या दोष। सबसे प्रमुख अंतर आदेश पर उच्च औसत लोडिंग है - अपने लक्ष्यों को पूरा करना। प्रारंभ में _विलंबित रिटर्न परोपकारिता_ कहा जाता है, पारस्परिक परोपकारिता किसी अजनबी के लिए खुद को बलिदान करने के बारे में नहीं है बल्कि सामाजिक साधनों के माध्यम से अपने भविष्य में निवेश करने के बारे में है। दूसरी ओर, किन परोपकारिता का अर्थ है अपने परिवार की मदद करना, भले ही आपके अपने खर्च पर, क्योंकि स्वार्थी जीन आपके दिल की धड़कन पर खींचते हैं। यह भावनात्मक लगाव पर किन परोपकारिता शब्दों की उच्च लोडिंग में स्पष्ट है, जो एश्टन की परिकल्पना का समर्थन करता है। लेकिन मुख्य क्रिया आदेश पर है, जहाँ से विषय-स्थान उपकरणों को पता लगाने के लिए डिज़ाइन किया गया था। विषय स्थान में नमूना लेने की लागत के कारण परिणाम अधिक शोधकर्ता पूर्वाग्रहों पर निर्भर होते हैं।

इन प्लॉट्स की व्याख्या करना चाय की पत्तियों को पढ़ने जैसा महसूस हो सकता है, लेकिन मैं यहाँ जो है उसमें लगभग 70% निश्चित हूँ। एक बात जो मुझे रोकती है वह यह है कि दो परोपकारिताओं का प्रतिनिधित्व अलग-अलग तरीकों से किया जाता है। किन शब्द सभी रिश्तों का वर्णन करते हैं (उदा. _माँ, पिता, भाई_), जबकि पारस्परिक शब्द रिश्तों (उदा. _पड़ोसी_) और दोहराए गए सकारात्मक-योग खेलों में फिट लक्षणों (उदा. _प्रतिशोधी, विवेकशील, सहयोगी_) का मिश्रण हैं। अनिश्चितता के बावजूद, क्या यह अच्छा नहीं होगा अगर एक दोपहर में मैंने एक प्रयोग चलाया जो लाखों लोगों के जीते हुए परोपकारिता अनुभव को जोड़ता है? जो पीढ़ियाँ सहमत हैं वह किसी को पितृत्व, बहनत्व, या पड़ोसपन बनाता है। हमेशा की तरह एक नए संकेत स्रोत के साथ, कोई हिप से शूटिंग शुरू करता है। अंततः वाइल्ड वेस्ट को वश में कर लिया जाता है; विधियाँ और ह्यूरिस्टिक्स उभरते हैं। सुधार के लिए बहुत जगह है। पाठक शब्द सेट को समायोजित कर सकते हैं और इस [कोलाब नोटबुक](https://colab.research.google.com/drive/13DA2IKQ9zRimGedww_09iGT6ehuYriVz?usp=sharing) का उपयोग करके कुछ ही मिनटों में नए परिणाम प्राप्त कर सकते हैं। कृपया ऐसा करें!

#### शब्द स्थान के लाभ

1. लेक्सिकल हाइपोथीसिस से जुड़ा हुआ। विकेंद्रीकृत सामाजिक वास्तविकता में आधारित।

2. कम रूपांतरण। प्रत्येक चरण हानिपूर्ण है और पूर्वाग्रह पेश करता है।

3. शब्द स्थान में रूपांतरण के बाद कम सांख्यिकीय गहन। (प्रवेश के लिए कम बाधा।)

4. प्रभावी नमूना आकार (जो भाषा मॉडल में रेडिट पर टिप्पणियों के माध्यम से योगदान करते हैं, किताबें लिखते हैं, या पबमेड लेख) अधिकांश अध्ययनों की तुलना में बहुत बड़ा और विविध है।

5. एनएलपी जानने वाले मनोविज्ञान पीएचडी के लिए बेहतर नौकरी की संभावनाएँ।

6. बहुभाषी/बहुसांस्कृतिक कार्य करना आसान। कुछ मॉडल एक साथ 100 भाषाओं पर प्रशिक्षित होते हैं (जो मेटा [घृणा भाषण फिल्टर](https://ai.facebook.com/blog/how-ai-is-getting-better-at-detecting-hate-speech/) को कुछ उदाहरणों वाली भाषाओं में प्रशिक्षित करता है)।

7. भाषा मॉडल [बेहतर](https://openai.com/blog/introducing-text-and-code-embeddings/) [होते](https://say-can.github.io) [रहते](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html) हैं।

8. खुला विज्ञान।

9. [आईआरबी से बचें](https://slatestarcodex.com/2017/08/29/my-irb-nightmare/)।

#### नुकसान

1. अधिक चलने वाले हिस्से। एक भाषा मॉडल में अरबों पैरामीटर होते हैं! हालांकि, अरबों न्यूरॉन्स और दर्जनों प्रशिक्षण निर्णय स्थिर प्रतिनिधित्व का परिणाम हो सकते हैं। कोई भी भाषा मॉडल जो अपनी नमक के लायक है, वह उपमा को पूरा कर सकता है "पति पत्नी के लिए है जैसे राजा ____ के लिए है"।

2. परिणामों को जनसांख्यिकी द्वारा तोड़ नहीं सकते। कभी-कभी यह जानना दिलचस्प होता है कि 25-30 के बीच के प्राथमिक विद्यालय के शिक्षकों का व्यक्तित्व क्या है। या यह जानने के लिए कि कुछ निर्माण का गिरफ्तारी रिकॉर्ड के साथ क्या संबंध है। शब्द स्थान में असंभव।

3. क्या भाषा मॉडल पूर्वाग्रहित नहीं हैं? खैर, आत्म-रिपोर्ट से ज्यादा नहीं।

4. परोपकारिता को शब्द वेक्टर के एक समूह के योग के रूप में परिभाषित करना (यानी, शब्दों का बैग) थोड़ा हैकी है। यहां सुधार के लिए पर्याप्त जगह है।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!ctzj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F455fdb70-3c84-4dfe-81bf-6bf6e676fd44_1600x1128.jpeg)मनोवैज्ञानिक विषय स्थान के माध्यम से 40 वर्षों तक भटकने से खुश हैं।

### **विदेशी देवता**

_"मुझे लगता है कि काफ्का सही थे जब उन्होंने कहा कि, एक आधुनिक व्यक्ति के लिए, राज्य नौकरशाही दिव्य आयाम के साथ एकमात्र शेष संपर्क है।"_ ~जिजेक, ए पेरवर्ट्स गाइड टू आइडियोलॉजी

वह यहाँ, निश्चित रूप से, आईआरबी के साथ अपील दाखिल करने की पारलौकिक भावना का वर्णन कर रहे हैं। मेरी एक भविष्यवाणी है। शब्द स्थान सिग्नल प्रोसेसिंग परिप्रेक्ष्य से अच्छा और सही काम करने वाला है, लेकिन इसका अपनाना उतना ही सुविधाजनक होगा जितना कि विनियमित नहीं होना। सहसंबंध यह है कि आईआरबी भाषा मॉडल को संवेदनशील घोषित करने वाली पहली सरकारी संस्था होगी।

<!-- CHUNK BREAK -->

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!6nGN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fedfc8bac-cf78-40f9-88d3-9a30066ff108_817x1600.jpeg)John spreading the good word space

### **मार्ग तैयार करना**

हम भाषा मॉडलों से संरचनाओं के बीच संबंध निकालना चाहते हैं। ऐसा करने के लिए जो संकेत जोड़ता है बजाय अधिक शोर के, इसके लिए बहुत सारे सत्यापन कार्य की आवश्यकता होती है। प्रारंभ में, इसका अर्थ है अच्छी तरह से स्थापित सर्वेक्षण परिणामों की तुलना करना। क्या वे शब्द वेक्टर का उपयोग करके पुनः प्राप्त किए जा सकते हैं? वे कहाँ विफल होते हैं? एक बार यह स्थापित हो जाने के बाद, हर पेपर जो "अधिक शोध की आवश्यकता है" पर समाप्त होता है, उसे शब्द स्थान में प्रश्न पूछने का तरीका खोजना चाहिए।

मैंने [RoBERTa](https://arxiv.org/abs/1907.11692) से व्यक्तित्व संबंध निकालने के लिए एक [विधि](https://psyarxiv.com/gdm5v/) को ठीक करने में एक वर्ष से अधिक समय बिताया, जो उस समय की अत्याधुनिक मॉडल थी। जल्द ही GPT-3 जारी किया गया और यह तुरंत बेहतर प्रदर्शन करने लगा। यह कि कंप्यूट डोमेन ज्ञान को पार कर जाता है, AI के भीतर एक बार-बार आने वाला [कड़वा सबक](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) है। कंप्यूट तेजी से बढ़ता है। यदि आप डोमेन ज्ञान का उपयोग करके सामान्य ML समाधान पर 30% लाभ प्राप्त कर सकते हैं, तो आप बस [कंप्यूट के पकड़ने का इंतजार](https://twitter.com/russelljkaplan/status/1513128016452337667) कर सकते हैं और सामान्य विधियों का उपयोग करके समान परिणाम प्राप्त कर सकते हैं। मनोविज्ञान के प्रश्नों को ऑफ-द-शेल्फ NLP मॉडलों से संबंधित करने के तरीके खोजना इसलिए एक अच्छा तरीका है। हर छह महीने या उससे अधिक समय में एक नया मॉडल सार्वजनिक किया जाता है जिसमें उल्लेखनीय रूप से बेहतर प्रदर्शन होता है। जो लोग शब्द स्थान को मान्य कर रहे हैं वे महान बुद्धियों के लिए मार्ग तैयार कर रहे हैं—[PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html), GPT-7, OSCar (**O** ptimal **S** entience **Car** tography)—जो मनोवैज्ञानिक सत्य बरसाने के लिए तैयार हैं।

प्राकृतिक भाषा दुनिया के बारे में साझा सिद्धांतों से भरी हुई है। अब जब हम उन्हें माप सकते हैं, तो क्या उन्हें साक्ष्य के रूप में उपयोग नहीं किया जा सकता?

यदि आपको यह दिलचस्प लगता है, तो कृपया साझा करें!

[साझा करें](https://www.vectorsofmind.com/p/in-the-beginning-was-the-word?action=share)