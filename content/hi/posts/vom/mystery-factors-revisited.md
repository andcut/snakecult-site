---
about:
- मन के वेक्टर
- ब्लॉग-संग्रह
author: Andrew Cutler
date: '2025-07-04'
description: भव्य सिद्धांतों से पीछे हटते हुए, यह पोस्ट रहस्यमय शब्दार्थ कारकों की
  पुनरीक्षण करती है। शब्द भारों से, क्या आप उस सामान्य सिद्धांत का वर्णन कर सकते हैं
  जो एक कारक को एक साथ रखता है? यह अभ्यास उस अल...
draft: false
keywords:
- मन-के-वेक्टर
- रहस्य
- कारक
- पुनरीक्षित
lang: hi
lastmod: '2025-07-09'
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '70046926'
original_url: https://www.vectorsofmind.com/p/mystery-factors-revisited
quality: 6
slug: mystery-factors-revisited
tags: []
title: रहस्यमय कारकों का पुनरीक्षण
translation_model: gpt-4o
---

*From [Vectors of Mind](https://www.vectorsofmind.com/p/mystery-factors-revisited) - images at original.*

---

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!mwT7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fce394826-55c7-436d-baf8-89fc9febae13_1024x1024.png)

महान सिद्धांतों से पीछे हटते हुए, यह पोस्ट रहस्यमय शब्दार्थीय कारकों पर पुनर्विचार करती है। शब्द लोडिंग्स से, क्या आप उस सामान्य सिद्धांत का वर्णन कर सकते हैं जो एक कारक को एक साथ रखता है? यह अभ्यास व्यक्तित्व मॉडलों की अंततः गुणात्मक प्रकृति को दर्शाता है। शब्द लोडिंग्स उत्पन्न करने के लिए उपयोग की गई सांख्यिकीय विधियों के बावजूद, एक मॉडल को अंततः शब्दों का उपयोग करके संप्रेषित करना पड़ता है, न कि संख्याओं का। इन विवरणों का उपयोग तब इन्वेंटरी (जैसे [BFI](https://fetzer.org/sites/default/files/images/stories/pdf/selfmeasures/Personality-BigFiveInventory.pdf)) उत्पन्न करने के लिए किया जाता है जो प्रत्येक निर्माण का अनुमान लगाते हैं।

प्रश्न में कारकों के लिए डेटा दो स्रोतों से आता है। एक कारक शब्द वेक्टर से है, और दूसरा पारंपरिक सर्वेक्षण दृष्टिकोण से। दोनों प्रक्रियाओं का वर्णन [यहां](https://vectors.substack.com/p/the-big-five-are-word-vectors) किया गया है। यदि आप एक बिना लेबल वाले प्लॉट पर कारकों का नामकरण करने का प्रयास करना चाहते हैं, तो नीचे पढ़ने से पहले [यह](https://vectors.substack.com/p/guess-the-factor) पोस्ट देखें।

## **रहस्यमय कारक 1**


**शीर्ष शब्द:**_सटीक, कठोर, निर्णायक, गंभीर, दृढ़_**बनाम** _मृदु, शिथिल, अनिर्णायक, भोला, मासूम_

टिप्पणीकारों ने इसे इस प्रकार वर्णित किया: सजगता, आत्मविश्वास, उद्योगशीलता, और उपस्थित क्रिया

अच्छा काम, टीम! यह मूल रूप से कारक को कवर करता है। इसे शब्द वेक्टर से डेटा के अनरोटेटेड तीसरे घटक के रूप में व्युत्पन्न किया गया था। अतीत में मैंने इसे ऑर्डर कहा है ताकि इसे बिग फाइव सजगता से अलग किया जा सके। वे समान हैं, लेकिन इसमें थोड़ा सा तीखापन है (जैसे _सटीक, प्रतिशोधी_)। ऑर्डर अपने लक्ष्यों को प्राप्त करने के बारे में है, चाहे कुछ भी हो जाए। बिग फाइव PC1 (the [PFP](https://vectors.substack.com/p/primary-factor-of-personality-part)) से विचलन लेता है और इसे ऑर्डर के साथ मिलाकर सजगता उत्पन्न करता है। इसलिए unforgiving ऑर्डर के साथ दृढ़ता से जुड़ा हुआ है, लेकिन सजगता पर तटस्थ है।

मेरी राय में, जो निर्माण किसी के अपने लक्ष्यों को पूरा करने की क्षमता को समाज के लक्ष्यों को पूरा करने की इच्छा के साथ जोड़ता है, वह स्थिति को भ्रमित करता है। मुझे लगता है कि IO अनुसंधान, उदाहरण के लिए, सजगता या दृढ़ता की तुलना में ऑर्डर का उपयोग करने से बेहतर होगा। रुचि के सहसंबंध (जैसे पदोन्नति) निश्चित रूप से ऑर्डर से अधिक सीधे संबंधित हैं। कभी किसी को शीर्ष पर नहीं मिला जो पूरी तरह से टीम प्लेयर था। हमेशा एक व्यक्तिगत तीखापन होता है।

## **रहस्यमय कारक 2**


**शीर्ष शब्द:**_अकल्पनीय, असंवेदनशील, नैतिक, सहानुभूतिपूर्ण, सैद्धांतिक_**बनाम** _चालाक, धूर्त, चतुर, रचनात्मक, बुद्धिमान_

टिप्पणीकारों ने इसे इस प्रकार वर्णित किया: नकारात्मक खुलापन, उद्योगशीलता, और शब्द का विश्वास।

यह थोड़ा पेचीदा है क्योंकि यह वास्तव में एक [क्लासिक पेपर](https://onlinelibrary.wiley.com/doi/abs/10.1002/\(SICI\)1099-0984\(199603\)10:1%3C61::AID-PER246%3E3.0.CO;2-D) से उपयोग किए गए डेटा का छठा अनरोटेटेड घटक है जो मूल रूप से बिग फाइव को परिभाषित करने के लिए उपयोग किया गया था। ~~यह वही है जो वे आपसे छिपा रहे हैं!~~ यह वही है जो कटौती में शामिल नहीं हुआ। यह दिलचस्प है कि उस डेटा में पांचवें और छठे दोनों कारक अनुभव के प्रति खुलेपन से संबंधित हैं। निश्चित रूप से, सांख्यिकीय रूप से मॉडल को पांच कारकों पर काटने के कारण हो सकते हैं। लेकिन गुणात्मक रूप से वह अंतिम कारक दो कारकों में विभाजित है, और केवल आधा संकेत शामिल किया गया था। यह किसी भी अन्य चीज़ से अधिक एक विचित्रता है। कोई विचार नहीं है कि क्या यह अन्य डेटासेट में भी लागू होता है।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!NlBJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcba348e-6ed3-442c-9506-6d3a8f7b5d4e_1201x1065.png)435 शब्दों को शब्द वेक्टर और सर्वेक्षणों के डेटा का उपयोग करके कारकित किया गया है। तीसरा अनरोटेटेड कारक शब्द वेक्टर (NLP) से चुना गया है और छठा सर्वेक्षणों से। शब्दों को फिट करने के लिए, केवल 150/435 प्रदर्शित किए गए हैं। इन्हें यादृच्छिक रूप से चुना गया था जो पिछली पोस्ट की तुलना में एक अलग उपसमुच्चय उत्पन्न करता है।

आशा है कि आपने इस छोटे से अभ्यास का आनंद लिया। ग्रेजुएट स्कूल में जब शब्द वेक्टर से शब्द लोडिंग्स निकालने की विधि विकसित कर रहा था, तो मुझे नहीं पता था कि परिणाम संकेत हैं या शोर। शुरुआत में, यह अधिकतर शोर था, और मैंने शब्द लोडिंग्स में एकीकृत मनोवैज्ञानिक निर्माण देखने की उम्मीद में कई घंटे बिताए। समय समाप्त हो रहा था और केवल पहले 2-3 NLP कारक बिग फाइव में स्थित किए जा सकते थे, लेकिन आपको ध्यान से देखना पड़ता था। [बिग टू](https://psycnet.apa.org/fulltext/1997-42257-010.html) की खोज की भावनात्मक राहत—जिसे मैं पूरी तरह से पुनः प्राप्त कर सकता था—उनके प्रति मेरी आत्मीयता का हिस्सा है। यह एक शोध प्रबंध में डालने के लिए एक अधिक सम्मोहक कहानी है बजाय इसके कि बिग फाइव का आधा हिस्सा कुछ-कुछ पुनः प्राप्त किया गया।

[Share Vectors of Mind](https://vectors.substack.com/?action=share)