---
about:
- मन के वेक्टर
- ब्लॉग-संग्रह
author: Andrew Cutler
date: '2025-07-04'
description: ठीक है, चलिए ज्ञान की बातों से थोड़ी राहत लेते हैं। वास्तव में मेरे पास
  कुछ मनोमिति पहले से तैयार थे, इससे पहले कि चेतना की स्पष्ट पुकार मुझे खींच ले। यह
  बस इतना कठिन है कि नज़रें हटाना...
draft: false
keywords:
- मन-के-वेक्टर
- व्यक्तित्व
- चारों-ओर
- दुनिया
lang: hi
lastmod: '2025-07-09'
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '108601152'
original_url: https://www.vectorsofmind.com/p/personality-around-the-world
quality: 6
slug: personality-around-the-world
tags: []
title: '# व्यक्तित्व दुनिया भर में'
translation_model: gpt-4o
---

*[Vectors of Mind](https://www.vectorsofmind.com/p/personality-around-the-world) से - मूल में चित्र।*

---

ठीक है, चलिए ज्ञान संबंधी विषयों से थोड़ी राहत लेते हैं। वास्तव में मेरे पास मनोमिति के कई विषय थे जिन्हें चेतना के स्पष्ट आह्वान द्वारा खींचे जाने से पहले कतार में रखा गया था। इसे नजरअंदाज करना बहुत कठिन है।

[*[छवि: मूल पोस्ट से दृश्य सामग्री]*](https://substackcdn.com/image/fetch/$s_!X2nA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62106fb3-6e73-444d-96f1-07b95ec828f9_1024x506.jpeg)[Ulysses and the Sirens](https://en.wikipedia.org/wiki/Ulysses_and_the_Sirens_\(Waterhouse\)), चित्रकार [John William Waterhouse](https://en.wikipedia.org/wiki/John_William_Waterhouse) द्वारा

मैंने इस ब्लॉग को मशीन लर्निंग के दृष्टिकोण से लेक्सिकल हाइपोथेसिस का अन्वेषण करने के लिए शुरू किया। व्यक्तित्व मॉडल एक भाषा में सबसे अधिक चर्चित लक्षणों को परिभाषित करते हैं, और हम इसे GPT के युग में बहुत बेहतर माप सकते हैं। शब्द वेक्टर या पारंपरिक सर्वेक्षणों से प्राप्त व्यक्तित्व मॉडल कुछ ही लक्षणों पर वापस आते हैं, विशेष रूप से बिग टू: सामाजिक आत्म-नियमन और गतिशीलता। इस पर एक ताज़ा जानकारी के लिए [The Big Five are Word Vectors](https://vectors.substack.com/p/the-big-five-are-word-vectors) और [The Primary Factor of Personality](https://vectors.substack.com/p/primary-factor-of-personality-part) देखें।

बिग फाइव को कई भाषाओं में स्वतंत्र रूप से पाया गया है, लेकिन भाषाओं के बीच तुलना हमेशा गुणात्मक होती है। शोधकर्ता तुर्की या जर्मन में व्यक्तित्व विशेषणों का सर्वेक्षण करते हैं, इसे कारक बनाते हैं, और कारकों को यह देखने के लिए देखते हैं कि क्या वे समान हैं। इस डेटा का उपयोग यह कहने के लिए नहीं किया जा सकता है कि "जर्मन में बहिर्मुखता अंग्रेजी की तुलना में विवेकशीलता से 15 डिग्री दूर है।" इतनी सटीकता के लिए, दोनों भाषाओं को कुछ आधार साझा करना होगा।

यदि आप कई भाषाओं में प्रश्न पूछते हैं तो आप उन्हें 1) एक द्विभाषी समूह खोजकर जोड़ सकते हैं जो दोनों भाषाओं में उत्तर दे सकता है या 2) यह मानकर कि शब्दों का अनुवाद 1:1 है (जैसे _fun_ स्पेनिश में _divertido_ के बराबर है)। पहले मामले में, एक मजबूत चयन प्रभाव होता है। क्या होगा यदि द्विभाषी लोग बेहतर शिक्षित होते हैं? दूसरा बस सच नहीं है। वास्तव में, भाषाओं को एक साथ कारक बनाने का कारण यह समझना है कि उनके बीच व्यक्तित्व संरचना कैसे भिन्न हो सकती है। यह मान लेना कि शब्द समान हैं, उद्देश्य को हरा देता है।

**[मेरे शोध](https://arxiv.org/abs/2203.02092) ने दिखाया कि आप अंग्रेजी में भाषा मॉडल से व्यक्तित्व संरचना निकाल सकते हैं। एक स्वाभाविक प्रश्न यह है कि जब आप अन्य भाषाओं को जोड़ते हैं तो यह कैसे बदलता है।** दर्जनों भाषाओं पर प्रशिक्षित मॉडल के साथ, इसका अन्वेषण करना काफी आसान हो जाता है। आप किसी भी संख्या में भाषाओं को एक ही आधार पर मैप कर सकते हैं।

## बिग टू, एक बार फिर

मैंने [XLM-RoBERTa](https://huggingface.co/xlm-roberta-base) का उपयोग व्यक्तित्व विशेषणों के बीच समानता असाइन करने के लिए किया। अजीब तरह से, यह मॉडल म्यांमार में नरसंहार का परिणाम है। मेटा के पास यह अवांछनीय स्थिति है जहां उन्हें उन स्थानों पर सामग्री को हटाने की आवश्यकता होती है जिनके बारे में उनके पास बहुत कम समझ होती है। तकनीकी रूप से, इसे ट्रांसफर लर्निंग समस्या कहा जाता है। वे अंग्रेजी (या किसी अन्य अच्छी तरह से स्रोत वाली भाषा) में एक घृणा भाषण वर्गीकरणकर्ता को प्रशिक्षित करना चाहेंगे, और फिर इसे अन्य भाषाओं पर लागू करना चाहेंगे। भाषा मॉडलिंग के अंधेरे युग (2018) में यह बहुत खराब काम करता था। बर्मी में "आइए समलैंगिकों को इकट्ठा करें और उन्हें मार दें" के लिए बोलचाल की भाषा उनके वर्गीकरणकर्ताओं को "इंद्रधनुष कम होने चाहिए" जैसा दिखती थी। यह, निश्चित रूप से, उनकी सामग्री मॉडरेशन से बच गया। NYT ने परिणाम की व्याख्या की: _**[A Genocide Incited on Facebook, With Posts From Myanmar's Military](https://www.nytimes.com/2018/10/15/technology/myanmar-facebook-genocide.html)**_

मेटा की प्रतिक्रिया एक भाषा मॉडल बनाने की थी जो किसी भी भाषा (खैर, 100 भाषाओं) को एक ही साझा स्थान में शब्द वेक्टरों पर बेहतर मैप कर सके। इस तरह अंग्रेजी में प्रशिक्षित एक घृणा भाषण वर्गीकरणकर्ता अन्य भाषाओं तक बेहतर तरीके से विस्तारित हो सकता है। (इसे ठीक करने के लिए कम बर्मी की आवश्यकता होती है।) इस मॉडल का उपयोग करके, मैंने चार भाषाओं में व्यक्तित्व शब्दों को एम्बेड किया: अंग्रेजी, स्पेनिश, फ्रेंच और तुर्की। नीचे पहले दो कारक हैं:

[*[छवि: मूल पोस्ट से दृश्य सामग्री]*](https://substackcdn.com/image/fetch/$s_!eLVQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd3ff00d-d96d-4e3b-ada4-640e3cd66089_1245x954.png)

ये विभिन्न भाषाओं को अलग करने का काम करते हैं। पहला कारक तुर्की को इंडो-यूरोपीय भाषाओं से अलग करता है। दूसरे कारक पर, रोमांस भाषाएँ निकटवर्ती हैं (हालाँकि तुर्की के भी करीब हैं)।

यह समझ में आता है। मॉडल को वाक्य के अगले शब्द की भविष्यवाणी करने के लिए प्रशिक्षित किया गया है, इसलिए इसमें स्वाभाविक रूप से भाषा-विशिष्ट जानकारी शामिल होगी। यदि कोई व्यक्ति स्पेनिश में बात कर रहा है तो वे अक्सर तुर्की में स्विच नहीं करते हैं। उम्मीद यह है कि वेक्टर-स्पेस में ऐसी दिशाएँ भी हैं जो व्यक्तित्व जानकारी से मेल खाती हैं।

यदि भाषाएँ काफी स्वतंत्र हैं, तो आपको अपनी स्वयं की गैर-ओवरलैपिंग समूहों में 4 भाषाओं को अलग करने के लिए कम से कम 3 आयामों की आवश्यकता होती है। आइए अगले प्रमुख घटकों की जाँच करें।

[*[छवि: मूल पोस्ट से दृश्य सामग्री]*](https://substackcdn.com/image/fetch/$s_!PRKA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5eb70bd2-8684-4844-94bd-aa12adc030bf_1256x954.png)

कारक 4 पहला कारक है जिसे भाषाओं को अलग करने के लिए नहीं सीखा गया था, और यह व्यक्तित्व का सामान्य कारक है! अंग्रेजी में: _प्रभुत्ववादी, निर्दयी, बाध्यकारी_ और _स्वार्थी_ **बनाम** _उदार, कोमल,_ और _विचारशील_। [मैंने तर्क दिया है](https://vectors.substack.com/p/primary-factor-of-personality-part) कि इस कारक को सबसे अच्छा समझा जाता है जैसे कि गोल्डन रूल का पालन करने की प्रवृत्ति। ईव थ्योरी ऑफ कॉन्शियसनेस वास्तव में [यह सोचने का परिणाम था कि हमारे विकासवादी इतिहास में यह किसके लिए चयन करेगा](https://vectors.substack.com/p/consequences-of-conscience)। कारक 5 भी व्यक्तित्व के बारे में है, उन्हें एक साथ प्लॉट करना:

[*[छवि: मूल पोस्ट से दृश्य सामग्री]*](https://substackcdn.com/image/fetch/$s_!pD64!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F192dc8f4-db5e-4d96-b8a5-ce16c1cbf1f6_1264x954.png)

हमें बिग टू मिलते हैं! कारक पांच (या व्यक्तित्व कारकों में से दो) गतिशीलता है: _साहसी, कल्पनाशील,_ और _उत्साही_ **बनाम** _सावधान, आरक्षित,_ और _कायर।_ यह आश्चर्यजनक है कि यह नियमित रूप से कैसे सामने आता है। **बिग टू पेपर पर [2,500 उद्धरण हैं](https://scholar.google.com/scholar?cites=11052969740325606797&as_sdt=2005&sciodt=0,5&hl=en), और फिर भी शोधकर्ता यह महसूस नहीं करते हैं कि वे केवल सामान्य व्यक्तित्व के पहले दो अप्रयुक्त कारक हैं।** यह सामान्य धारणा कि वे किसी तरह बिग फाइव के साथ एक पदानुक्रमित संबंध में मौजूद हैं, शोधकर्ताओं के बिग फाइव इन्वेंटरी बनाने के तुरंत बाद सीधे भाषा से निपटने को छोड़ने से आती है। तब से, बुनियादी या सामान्य व्यक्तित्व को समझने का कोई भी प्रयास बिग फाइव के संदर्भ में किया जाना चाहिए। लेकिन शब्द पहले आए, और भाषा मॉडल अब उस मौलिक स्तर पर भाषा का विश्लेषण करना आसान बनाते हैं।

[साझा करें](https://www.vectorsofmind.com/p/personality-around-the-world?action=share)

## हमें और गहराई में जाना होगा

रूसी और फारसी को जोड़ने से वही कारक मिलते हैं:

[*[छवि: मूल पोस्ट से दृश्य सामग्री]*](https://substackcdn.com/image/fetch/$s_!IIKx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F976f1c11-fd97-4184-a74a-a384a09b0579_2078x1715.png) शब्दों को बेहतर ढंग से देखने के लिए छवि डाउनलोड करें और ज़ूम इन करें।

मेरे आलसी इंजीनियर मानकों के अनुसार यह काफी श्रमसाध्य है क्योंकि इसके लिए प्रत्येक भाषा के लिए एक अच्छा प्रॉम्प्ट ढूंढना आवश्यक है। मैंने इसे सही करने के लिए गूगल ट्रांसलेट और मूल वक्ताओं के साथ काम किया, और आप देख सकते हैं कि कारक 4 पर फारसी वितरण अभी भी बंद है। मेरा अनुमान है कि मेरी विधि जो किसी भी कारक को अनदेखा करती है जो साझा नहीं किया गया है, इतनी अधिक भाषाओं के लिए बहुत जंकी है। कारक 4 शायद जीएफपी के रूप में उपयोग किया जाता है, और फारसी को अलग करने के लिए भी (थोड़ा सा)। इन कारकों को शुद्ध रखने के लिए कुछ भी नहीं है, हम वास्तव में भाग्यशाली हैं कि वितरण उतना ही अच्छा व्यवहार कर रहा है जितना यह है। कुछ पूर्व-प्रसंस्करण करना (जैसे प्रत्येक भाषा क्लस्टर को शून्य-मतलब करना) इसे हल कर सकता है।

मेरी जानकारी के अनुसार यह पहली बार है जब कई भाषाओं को एक साथ कारक बनाया गया है। यह केवल अंग्रेजी और स्पेनिश पर परिणामों के साथ प्रकाशित किया जा सकता था और यहां मैंने छह तक पहुंच बनाई, जिसमें दो गैर-इंडो-यूरोपीय भाषाएं शामिल हैं। यह बिग टू की प्रकृति पर भी प्रकाश डालता है, जो मनोमिति में सबसे लोकप्रिय—और गलत समझे गए—संरचनाओं में से एक है।

## कमियां

मैंने यह शोध लगभग सबसे बेवकूफ तरीके से किया। मैंने एक ईएसएल गाइड में 100 व्यक्तित्व शब्द पाए, और फिर उन्हें गूगल ट्रांसलेट का उपयोग करके अन्य भाषाओं में अनुवादित किया। यदि डुप्लिकेट थे, तो मैंने उन्हें हटा दिया। यह उतना बुरा नहीं है जितना लगता है। पहले दो कारक अंग्रेजी में लगभग अपरिवर्तित रहते हैं चाहे आप 100 या 500 शब्दों का उपयोग करें। लेकिन, अगर यह एक वास्तविक पेपर होता, तो आप स्पष्ट रूप से प्रत्येक शब्दावली में स्वतंत्र रूप से शब्दों का एक सेट विकसित करना चाहेंगे। कई अन्य कमियां हैं:

**पर्याप्त भाषाएं नहीं!** अगर मैंने इसे प्रकाशित किया, तो मैं उन दर्जनों और भाषाओं को जोड़ना चाहूंगा जिनका व्यक्तित्व विज्ञान में आमतौर पर अध्ययन नहीं किया जाता है। वास्तव में, यही कारण है कि मैंने इसे प्रकाशित करने का कभी प्रयास नहीं किया। यह बहुत काम है और इसके लिए कई एशियाई भाषाओं के मूल वक्ताओं की आवश्यकता होगी।

**प्रशिक्षण डेटा द्वारा विकृत बहु-भाषी मॉडल।** भाषा मॉडल को वाक्य के अगले शब्द की भविष्यवाणी करने के लिए प्रशिक्षित किया जाता है। यदि आप कई भाषाओं के साथ प्रशिक्षण लेते हैं, तो मॉडल कुछ ज्ञान स्थानांतरित करने का प्रयास करेगा। हालांकि, छोटी भाषाओं के लिए यह बेहतर-स्रोत वाली भाषाओं (अंग्रेजी, चीनी, रूसी, आदि) के भीतर उनकी अर्थों को मजबूत करने जैसा दिख सकता है।

**प्रश्न शोधकर्ता की स्वतंत्रता की डिग्री हैं।** मैं जिस विधि का उपयोग शब्दों को एम्बेड करने के लिए करता हूं वह है "मेरा व्यक्तित्व <mask> और [शब्द] के रूप में वर्णित किया जा सकता है" जहां [शब्द] व्यक्तित्व शब्दों में से एक है। जिस तरह से वाक्य लिखा गया है, उसके कारण, मॉडल शुद्ध व्यक्तित्व जानकारी को मास्क टोकन पर लोड करता है और फिर इसे एम्बेड करता है। अपने शोध प्रबंध में, मैंने पाया कि यह सबसे अच्छा काम करता है। बेशक, इसके अनंत रूपांतर हैं, और आपको एक का चयन करना होगा। सैद्धांतिक रूप से एक शोधकर्ता के मन में एक विशेष परिणाम हो सकता है, और फिर एक ऐसा प्रश्न ढूंढ सकता है जो उसका समर्थन करता हो। IMO यह बहुत अधिक जोखिम नहीं है, इस तथ्य को देखते हुए कि यह परिणाम सर्वेक्षण विधियों के समान है। हमारे पास इस बात की काफी मजबूत पूर्वधारणा है कि हम कारक विश्लेषण के साथ किस प्रकार की व्यक्तित्व संरचना पाते हैं। इस विधि का इसे पुनः प्रस्तुत करना इस बात का प्रमाण है कि विधि काम करती है।

**पुराना भाषा मॉडल।** मैंने यह काम 2 साल पहले किया था, बहुत पहले GPT-4 आया था। सरल समय।

## निष्कर्ष

यदि मैं अभी भी अकादमिक क्षेत्र में होता, तो यह मेरा शोध एजेंडा होता। जितनी संभव हो उतनी भाषाओं को जोड़ें, और यह समझने की कोशिश करें कि विधि को पक्षपाती बनाने के सभी तरीके क्या हो सकते हैं। अंत में, यह बिग फाइव से बेहतर सार्वभौमिक व्यक्तित्व मॉडल तैयार कर सकता है। यह हमें यह बेहतर ढंग से समझने में मदद करेगा कि हम कौन हैं, और शायद हम कहां से आए हैं। क्योंकि यह भाषा है जो अब हमारी प्रजातियों को परिभाषित करती है, और यह भाषा थी जिसने अतीत में हमारे मनोविज्ञान को आकार दिया। हम आदतन सामाजिक हैं क्योंकि हजारों साल पहले अपनी प्रतिष्ठा का प्रबंधन करने में विफल रहना मरने के समान था। व्यक्तित्व मॉडल भाषा के मानचित्र हैं; वे हमारे मन के विकास में वेक्टर हैं।

[अभी सदस्यता लें](https://www.vectorsofmind.com/subscribe?)

[*[छवि: मूल पोस्ट से दृश्य सामग्री]*](https://substackcdn.com/image/fetch/$s_!MDwl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F935dcb92-8e91-41c3-9630-2a80f2bc9a06_1024x1024.png)