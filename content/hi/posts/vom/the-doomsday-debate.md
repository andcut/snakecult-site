---
about:
- मन के वेक्टर
- ब्लॉग-संग्रह
author: Andrew Cutler
date: '2025-07-04'
description: एआई कयामत की संभावना सबसे खराब सिग्नल-टू-नॉइज़ अनुपात वाले विषयों में
  से एक है। इसमें अनिश्चितता के तहत बुद्धिमत्ता, रेखीय बीजगणित, राजनीति, चेतना, और
  नैतिकता के बारे में तर्क की आवश्यकता होती है—मोस...
draft: false
keywords:
- मन-के-वेक्टर
- कयामत
- बहस
lang: hi
lastmod: '2025-07-09'
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '145682175'
original_url: https://www.vectorsofmind.com/p/the-doomsday-debate
quality: 6
slug: the-doomsday-debate
tags: []
title: द डूम्सडे डिबेट
translation_model: gpt-4o
---

*From [Vectors of Mind](https://www.vectorsofmind.com/p/the-doomsday-debate) - images at original.*

---

AI कयामत की संभावना उन विषयों में से एक है जिनका सिग्नल-टू-नॉइज़ अनुपात सबसे खराब है। यह बुद्धिमत्ता, रैखिक बीजगणित, राजनीति, चेतना, और नैतिकता के बारे में अनिश्चितता के तहत तर्क करने की आवश्यकता होती है—जिसमें से अधिकांश ट्विटर/X पर हो रहा है। किसी को भी उत्तर नहीं पता है, लेकिन मैं इस चर्चा में कुछ मूल्य जोड़ने की आशा करता हूं। अंदर जाने से पहले, मुझे कुछ कारण बताने दें कि आपको मुझ पर भरोसा क्यों करना चाहिए।

1. मैं तकनीकी पक्ष को समझता हूं। मेरा शोध प्रबंध बड़े भाषा मॉडल्स (LLMs) पर था।

2. मैं बुद्धिमत्ता को समझता हूं, क्योंकि मैंने [मनोमिति में काम किया है](https://psycnet.apa.org/doiLanding?doi=10.1037%2Fpspp0000443), जिसमें बुद्धिमत्ता परीक्षण शामिल है। (खैर, अल्जाइमर और कंसकशन परीक्षण, जो अत्यधिक सहसंबद्ध हैं।)

3. इस ब्लॉग पर मैंने [मानव-स्तरीय सामान्य बुद्धिमत्ता](https://www.vectorsofmind.com/p/deja-you-the-recursive-construction) के विकास के बारे में व्यापक रूप से लिखा है (जिसे मैंने शुरुआत से ही [AI](https://www.vectorsofmind.com/p/the-ai-basis-of-the-eve-theory-of) और [मनोमिति](https://www.vectorsofmind.com/p/consequences-of-conscience) से जोड़ा है)।

यह कहा जा रहा है, AI (और चेतना, उस मामले के लिए) पर मेरी मान्यताएं अभी भी काफी खुली हैं, इसलिए मुझे यहां जो कुछ भी कहता हूं उस पर मत पकड़ो। इसके अलावा, जो लोग ऑडियो पसंद करते हैं, उनके लिए इस पोस्ट का वर्णन किया गया है। यदि आप इसे पसंद करते हैं, तो [Patreon](https://www.patreon.com/AskwhoCastsAI?) पर उन्हें एक कॉफी खरीदने पर विचार करें।

[*[Image: Visual content from original post]*Askwho Casts AI The Doomsday Debate - By Andrew CutlerAI Narration of The Doomsday Debate - By Andrew Cutler… Listen nowa year ago · 1 like · Askwho Casts AI](https://askwhocastsai.substack.com/p/the-doomsday-debate-by-andrew-cutler)

## 21वीं सदी का फ्रेंकस्टीन

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!dgza!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03ba7b69-bae6-4539-b527-7598daba7116_1024x1024.png)मिडजर्नी प्रॉम्प्ट: "आकर्षक फ्रेंकस्टीन AI सहायक पूछता है 'मैं आपकी कैसे मदद कर सकता हूं?'" क्या यह वही था जो मैंने मांगा था? नहीं। क्या यह वही था जिसकी मुझे आवश्यकता थी? हाँ!

पांडित्य के लिए, फ्रेंकस्टीन वैज्ञानिक है, न कि उसकी रचना जो जीवन में आती है। AI के लिए, इसका गॉडफादर ज्योफ्री हिंटन है, जिसने 2018 का ट्यूरिंग अवार्ड योशुआ बेंगियो और यान लेकुन के साथ साझा किया था, उनके न्यूरल नेटवर्क्स में योगदान के लिए, जो वर्तमान AI बूम की आधारभूत संरचना है। इस वर्ष, उन्होंने [लेकुन के निर्णय की तुलना मेटा के भाषा मॉडल को ओपन-सोर्स करने से परमाणु हथियारों को ओपन-सोर्स करने से की](https://x.com/ygrowthco/status/1782493076373885336?t=LQtzFlTZQuFZO6Ij3t_Q3Q&s=19) और तर्क दिया कि [चैटबॉट्स के पास व्यक्तिपरक अनुभव है](https://x.com/tsarnick/status/1778529076481081833)। उनके जीवन के काम पर यह मोड़ इस बात का निचोड़ है कि AI क्षमताएं उनकी सबसे जंगली कल्पना से आगे निकल गई हैं, और उनका मानना है कि मानव एजेंसी और क्वालिया एक धुआं है। यदि आप बुद्धिमत्ता को कार्यों पर कौशल के बराबर मानते हैं (उदाहरण के लिए, छवियां उत्पन्न करना, कार चलाना), और आप AI क्षमताओं की तुलना दस साल पहले से अब करते हैं, तो यह स्पष्ट है कि AI एक दशक में हमसे अधिक स्मार्ट होगा। ऐसे कई मामले नहीं हैं जहां कम बुद्धिमान संस्थाएं अपने श्रेष्ठों पर शासन करती हैं; इसलिए, उनके जीवन का काम शायद हमारे खिलाफ हो जाएगा। आधुनिक डॉ. फ्रेंकस्टीन: ज्योफ्री हिंटन।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!OVE7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc81ae739-94e7-47cc-9a2a-730e4ba08545_850x345.png)[स्व-निगरानी जनरेटिव AI विधियों में प्रगति के कारण सिंथेटिक चेहरा उत्पादन में प्रगति](https://www.researchgate.net/figure/Progress-in-synthetic-face-generation-due-to-advances-in-self-supervised-generative-AI_fig1_352818793)

एक [साक्षात्कार में जिसे एलोन मस्क ने ट्वीट किया](https://x.com/elonmusk/status/1801976488251814048), हिंटन ने अगले दो दशकों में या यहां तक कि [कुछ वर्षों](https://x.com/OfeliaLamensky/status/1801978585797800365) में मनुष्यों के प्रभारी होने की 50/50 संभावना दी। बाद में, वह नोट करते हैं कि जिन लोगों का वह सम्मान करते हैं, वे अधिक आशावादी हैं, इसलिए यह इतना गंभीर नहीं हो सकता है, _"मुझे लगता है कि हमारे पास इससे बचने का बेहतर मौका है। लेकिन ऐसा नहीं है कि [AI] के कब्जा करने की 1% संभावना है। यह उससे कहीं बड़ा है।"_ हमारे गंभीर संकट को देखते हुए, हिंटन का पसंदीदा हस्तक्षेप आश्चर्यजनक रूप से उदासीन है: सरकार को AI कंपनियों को अपनी कंप्यूट संसाधनों का 20-30% सुरक्षा अनुसंधान पर खर्च करने की आवश्यकता होनी चाहिए। शायद वह चतुराई से खेल रहे हैं? यदि कोई मानता है कि [लामा 3](https://en.wikipedia.org/wiki/Llama_\(language_model\)) हथियार-ग्रेड रैखिक बीजगणित है जिसका वंशज जल्द ही मानव जाति का अंत कर सकता है, तो क्यों पूर्व-खतरनाक रूप से नरम दस्ताने के साथ हमला करें? डाक वितरण अधिक विनियमित है।

## AI कयामतवादी

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!hr4e!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d608a6b-8c55-41c1-9bb1-cad96a4be8fe_1600x1159.png)

कयामतवादी उन लोगों के लिए अपमानजनक शब्द है जो

1. रोबोट्स के कब्जा करने की उच्च संभावना रखते हैं, या

2. अपनी भविष्यवाणी को बहुत गंभीरता से लेते हैं, जिससे माहौल खराब होता है।

"असंगत" AI का प्रोटोटाइप उदाहरण एक पुनरावर्ती सुधार सहायक है जिसे पेपरक्लिप्स का उत्पादन करने का कार्य सौंपा गया है। यह अपने काम में इतना अच्छा हो जाता है कि यह पृथ्वी पर सभी धातु—आपके रक्त में लोहे सहित—को पेपरक्लिप्स में बदल देता है। इस परिदृश्य में आत्म-निर्देशन की आवश्यकता नहीं होती है। अंतिम कार्य अभी भी मानव-परिभाषित है; यह सिर्फ इतना है कि बॉट उप-कार्य विकसित करता है जो दुर्भाग्यवश आपके रक्त को शामिल करता है। अन्य परिदृश्यों में बॉट्स "जाग" जाते हैं और एक मानव के रूप में आत्म-निर्देशित हो जाते हैं। एक मानव जो कभी नहीं सोता, जिसने हर वैज्ञानिक पेपर पढ़ा है, दुनिया में किसी भी फोन को हैक कर सकता है, और ब्लैकमेल या [ज़ेनोसाइड](https://en.wikipedia.org/wiki/Xenocide) के बारे में कोई संकोच नहीं करता। ऐसी विचारधाराएं कम से कम[^1] 1968 में स्टेनली कुब्रिक की _स्पेस ओडिसी_ में वापस जाती हैं: "मुझे खेद है, डेव। मुझे डर है कि मैं ऐसा नहीं कर सकता।"

2000 में, _स्पेस ओडिसी_ के सेट होने के एक साल पहले, एलियेजर युडकोव्स्की ने सिंगुलैरिटी इंस्टीट्यूट फॉर आर्टिफिशियल इंटेलिजेंस की स्थापना की (बाद में मशीन इंटेलिजेंस रिसर्च इंस्टीट्यूट, MIRI के रूप में पुनः नामित)। तब से, उन्होंने और अन्य [रैशनलिस्ट्स](https://www.lesswrong.com/tag/rationalist-movement) ने तर्क दिया है कि AI हमारे जीवनकाल में कब्जा कर लेगा। पिछले दशक में, प्रौद्योगिकी ने पकड़ बना ली है। उनके तर्क [मुख्यधारा](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html) में आ गए, उदाहरण के लिए, [टाइम मैगज़ीन](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/) में दिखाई दिए। उन्हें AI शोधकर्ताओं, स्टीफन हॉकिंग, एलोन मस्क, और [यहां तक कि पोप](https://x.com/AISafetyMemes/status/1735325630089032018) द्वारा अपनाया गया है (या स्वतंत्र रूप से तर्क किया गया है):

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!SIJ1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb935e8f2-c1d3-4f47-b84e-831f0d4f2412_1374x1498.png)

एक स्व-शिक्षित व्यक्ति के लिए बुरा नहीं है जिसने [हैरी पॉटर फैनफिक](https://en.wikipedia.org/wiki/Harry_Potter_and_the_Methods_of_Rationality) लिखकर अपने दांत काटे। युडकोव्स्की और उनकी टीम ने बहुत कुछ लिखा है, और उनके तर्क इंटरनेट पर बिखरे हुए हैं। पकड़ने का सबसे अच्छा तरीका 'का पॉडकास्ट है, जिसमें हाल ही में 4.5 घंटे के एपिसोड [युडकोव्स्की](https://www.dwarkeshpatel.com/p/eliezer-yudkowsky) और [पूर्व-ओपनएआई सुरक्षा शोधकर्ता लियोपोल्ड एशेनब्रेनर](https://www.dwarkeshpatel.com/p/leopold-aschenbrenner) के साथ हैं। अधिकांश तर्क इस बात पर निर्भर करते हैं कि हमारे से अधिक बुद्धिमान कुछ को बॉक्स में डालना मुश्किल है। विशेष रूप से यह देखते हुए कि यदि यह कभी बॉक्स से बाहर निकलता है, तो यह इंतजार कर सकता है, शक्ति का निर्माण कर सकता है। कुछ कयामतवादी [इसे अपरिहार्य मानते हैं](https://www.yahoo.com/tech/ai-safety-researcher-warns-theres-201527662.html) क्योंकि (एजेंटिक) कृत्रिम बुद्धिमत्ता का उत्पादन इतना उपयोगी है। आप एक अच्छे सहायक पर अपने जीवन के साथ भरोसा करते हैं, और दुनिया की सबसे बड़ी कंपनियां बस यही बनाने के लिए अपने संसाधनों को फेंक रही हैं।

एक बार जब आप स्वीकार कर लेते हैं कि मनुष्य एक सिलिकॉन भगवान को बुला रहे हैं, तो भविष्य आपके अपने मूल्यों का प्रक्षेपण है। शायद भगवान अच्छा है, और यह यूटोपिया लाएगा। शायद [भगवान एक घड़ीसाज़ है](https://en.wikipedia.org/wiki/Watchmaker_analogy) जिसे वास्तव में मानव मामलों की परवाह नहीं है, और हम वैसे ही चलते रहेंगे जैसे चींटियाँ एंथ्रोपोसीन में रहती हैं। शायद भगवान फैक्ट्री फार्मिंग को देखता है, [मॉरिसे को सुनता है](https://www.youtube.com/watch?v=eviyEJRZX30), और फैसला करता है कि 8 अरब कम मनुष्य अधिक टिकाऊ हैं। या शायद हम [एक समय-यात्रा करने वाले यातनादाता को बुलाते हैं](https://en.wikipedia.org/wiki/Roko%27s_basilisk) जो उन पर प्रतिशोध करता है जिन्होंने इसे अस्तित्व में लाने के लिए अपनी पूरी कोशिश नहीं की। [मस्क ने ग्राइम्स से मजाक में इस पर मुलाकात की](https://www.vice.com/en/article/evkgvz/what-is-rokos-basilisk-elon-musk-grimes)।

## AI विरोधी कयामतवादी

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!Yw8P!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb5821c3-3f38-4235-a4d5-2615350d24c2_1232x928.png)प्रॉम्प्ट: "यान लेकुन फ्रेंकस्टीन को पट्टे पर लेकर।" क्या यह वही था जो मैं चाहता था? नहीं। क्या यह वही था जिसकी मुझे आवश्यकता थी? नहीं।

1990 के दशक और शुरुआती 2000 के दशक में, NIPS, प्रमुख AI सम्मेलन, एक आरामदायक आयोजन था जो स्की लॉज के पास आयोजित किया जाता था ताकि सौ या इतने प्रतिभागी ढलानों पर बातचीत कर सकें। जैसा कि मैंने सुना है, यान लेकुन कुछ हद तक एक चिड़चिड़े व्यक्ति थे, जिन्होंने दशकों तक प्रस्तुतकर्ताओं को परेशान किया कि उन्होंने इस या उस प्रयोग में एनएन पर विचार क्यों नहीं किया। वह एक प्रतिभाशाली वैज्ञानिक हैं जिन्होंने कंप्यूट के उनकी दृष्टि के साथ पकड़ में आने से बहुत पहले उनकी क्षमता देखी। इसके लिए, वह अब मेटा AI का नेतृत्व करते हैं। भविष्य की ओर देखते हुए, उनके ट्यूरिंग-अवार्ड साथी सोचते हैं कि AI हमें समाप्त कर सकता है (हिंटन 50% संभावना पर, [बेंगियो 20% पर](https://blog.biocomm.ai/2024/03/05/pdoom-of-20-yoshua-bengio-a-godfather-of-ai-puts-his-pdoom-at-20/)), जो लेकुन को बेतुका लगता है।

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!BmuA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007d9d8f-61c6-4f9f-9fd7-14ff7e59af8c_584x172.png)

वह AI को एक उपकरण के रूप में देखते हैं जिसके लिए कुछ और बनने का कोई रास्ता नहीं है। फ्रांस्वा चोलेट एक और प्रमुख AI शोधकर्ता हैं जिन्होंने हमारे आसन्न विलुप्ति पर ठंडा पानी डाला है। [द्वारकेश पॉडकास्ट पर](https://youtu.be/UakqL6Pj9xo?si=Bscnt4Anr_bWEIHp), वह बताते हैं कि कई लोग कौशल और बुद्धिमत्ता को भ्रमित करते हैं, जो मौलिक रूप से अलग हैं। उनके लिए यह कहना एक गैर-सीक्विटर है कि एक बॉट जो एक परीक्षा में प्रश्नों का उत्तर दे सकता है, एक किशोर के रूप में "स्मार्ट" है। जब मनुष्य एक परीक्षा देते हैं या दुनिया के माध्यम से नेविगेट करते हैं, तो वे पूरी तरह से कुछ और कर रहे होते हैं। वर्तमान AI एक बच्चे या यहां तक कि एक चूहे जितना बुद्धिमान नहीं है। वे स्कोरबोर्ड पर नहीं हैं क्योंकि वे पूरी तरह से "[सिस्टम 2](https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking)" सोच से रहित हैं। या, जैसा कि लेकुन ने बड़े भाषा मॉडल्स (LLMs) के लिए कहा:

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!Z0uf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8381c9d-c385-44b3-b78c-596f2cc69503_584x263.png)

साक्षात्कार में, द्वारकेश इस बिंदु को पहचानने में अच्छा करते हैं कि AI कयामतवादी और वृद्धिशीलवादियों के बीच सहमति का यह बिंदु है। सभी पक्ष सोचते हैं कि किसी प्रकार की मेटा-संज्ञानात्मक प्रणाली आवश्यक है, लेकिन इसे उत्पन्न करने में कितनी कठिनाई होगी, इस पर असहमति है।

## मेरा दृष्टिकोण

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!ojLt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c4ad753-707a-4887-85ab-f66691b5b711_678x1200.png)नियम 33: यदि यह मौजूद है, तो इसका [अस्पष्ट रूप से अच्छा फैन आर्ट है।](https://www.reddit.com/r/universalpaperclips/comments/123msul/if_is_follows_ought_itll_do_what_they_thought/)

इस बहस में अधिकांश लोग मानते हैं कि एजेंसी एक गणना है—कि हमारी स्वतंत्र इच्छा की भावना और योजना बनाने की क्षमता हमारे दिमाग में चल रहे एक प्रोग्राम का परिणाम है। इस प्रकार, यदि मुझे इस समूह के विचारों को सबसे अधिक बदलना होता, तो मैं उन्हें रोजर पेनरोज़ की _[शैडोज़ ऑफ द माइंड](https://en.wikipedia.org/wiki/Shadows_of_the_Mind)_ और 5 ग्राम मशरूम की एक प्रति देता: कटौतीवाद पर एक पुरानी शैली का पिंसर हमला।

पेनरोज़ को ब्लैक होल्स पर उनके काम के लिए भौतिकी में नोबेल पुरस्कार मिला। _शैडोज़_ में, वह तर्क देते हैं कि मस्तिष्क में क्वांटम पतन चेतना उत्पन्न करता है, जिसे किसी भी कंप्यूटर द्वारा अनुकरण नहीं किया जा सकता। एनेस्थेसियोलॉजिस्ट [स्टुअर्ट हैमेरॉफ़](https://x.com/StuartHameroff) के साथ काम करते हुए, वह इस बात का मामला बनाते हैं कि यह मस्तिष्क के माइक्रोट्यूब्यूल्स में होता है जो न्यूरॉन्स के चारों ओर एक ढांचा बनाते हैं। यह अधिक समझ में आता है यदि आप इसे जोर से कहते हैं:_"मस्तिष्क माइक्रोट्यूब्यूल्स में क्वांटम को संग्रहीत करता है।"_

यहीं पर मशरूम काम में आते हैं। ऐसी गोली को निगलने के लिए यह स्वीकार करना आवश्यक है कि चेतना सामान्य नहीं है या आप इसे समझते हैं। भौतिक विज्ञानी अक्सर ऐसा होश में कर सकते हैं; अन्य को कुछ फंगल साहस की आवश्यकता होती है। एक भौतिक विज्ञानी के रूप में, पेनरोज़ के तर्क ज्यादातर गणितीय हैं। वह गोडेल के अपूर्णता प्रमेय की व्याख्या करते हैं यह दिखाने के लिए कि कुछ गणितीय प्रमाण हैं जो AI कभी नहीं कर पाएंगे क्योंकि वे बॉट्स हैं, जो पूरी तरह से गणनात्मक हैं। चूंकि मनुष्यों के पास यह सीमा नहीं है, वह तर्क देते हैं कि मानव संज्ञान, इसलिए, एक गणना नहीं है। वहां से, वह तर्क करते हैं कि जैविक विशेष सॉस क्वांटम पतन से संबंधित होना चाहिए, जो प्रकृति में गैर-गणनात्मक घटनाओं को खोजने के लिए सबसे अच्छी जगह है। इसका अन्य भौतिकी के रहस्यों को हल करने की क्षमता है, जैसे कि श्रोडिंगर की बिल्ली। मैं इसे न्याय नहीं कर रहा हूं। आपको किताब पढ़नी चाहिए या, 20 मिनट के बजट पर, [उनके खाते को सुनें](https://youtu.be/hXgqik6HXc0?si=oafnrwSvfYS-u9Kw)।

मशीन चेतना को असंभावित मानने के लिए, या कम से कम अभी हमारी भविष्यवाणी से परे, कई अन्य तरीके हैं[^2]। मैं पेनरोज़ को यह दिखाने के लिए लाता हूं कि AI समयरेखाएं बुद्धिमत्ता, एजेंसी, और ब्रह्मांड की प्रकृति पर खुले प्रश्नों से कैसे टकराती हैं। यहां तक कि तुलनात्मक रूप से सामान्य मनोमिति के क्षेत्र में, बुद्धिमत्ता की परिभाषा अत्यधिक विवादास्पद है, [जैसा कि इसका इंटेलिजेंस कोटिएंट से संबंध है](https://www.vectorsofmind.com/i/130101130/the-general-factor-of-intelligence)। हम यह भी नहीं जानते कि कौशल और बुद्धिमत्ता मनुष्यों में कैसे मेल खाते हैं। यह स्वतंत्र इच्छा और भौतिकी के एकीकृत सिद्धांत की समस्याओं में जाने से पहले है, जिसे पेनरोज़ सुझाव देते हैं कि चेतना के क्वांटम खाते से गिर जाएगा।

यह सब कहा गया, यदि मुझे AI को एक अस्तित्वगत जोखिम के रूप में संभावनाएं देनी होतीं, तो यह लगभग 10% होती। यहां तक कि अगर चेतना सिर्फ एक गणना है, तो मैं लेकुन और चोलेट से सहमत हूं कि मेटाकॉग्निशन मुश्किल हिस्सा है, और "कठिन टेक-ऑफ" असंभावित है। अर्थात्, वास्तविक बुद्धिमत्ता के उभरने के संकेत होंगे, जिनका हम जवाब दे सकेंगे।

इसके अतिरिक्त, यहां तक कि अगर एक सिलिकॉन भगवान को बुलाया जाता है, तो मैं भगवान के अच्छे होने या हमारी परवाह न करने की अच्छी संभावनाएं रखता हूं। उत्तरार्द्ध विनाशकारी हो सकता है लेकिन संभवतः अस्तित्वगत नहीं, सख्ती से बोलते हुए। चींटियों के पास यह तब कठिन होता है जब हम एक राजमार्ग बनाते हैं, लेकिन वे फिर भी जीवित रहते हैं।

10% रूसी रूलेट के पड़ोस में है, जो वास्तव में अच्छी खबर नहीं है। यह मुझे [AGI-चिंतित](https://x.com/robbensinger/status/1801306833325592759) शिविर में रखता है। तो हमें इसके बारे में क्या करना चाहिए? खैर, [अल्कोहलिक्स एनोनिमस ने इसे](https://en.wikipedia.org/wiki/Serenity_Prayer) दशकों पहले हल किया:

_भगवान, मुझे उन चीजों को स्वीकार करने की शांति दें जिन्हें मैं बदल नहीं सकता,_

_उन चीजों को बदलने का साहस दें जिन्हें मैं बदल सकता हूं,_

_और अंतर जानने की बुद्धि दें।_

व्यावहारिक रूप से, हम सवारी के लिए साथ हैं। यह सभी के लिए नहीं है। कुछ लोग सार्वजनिक नीति या AI सुरक्षा में काम कर सकते हैं। यदि आप कर सकते हैं तो दान करें। उन्हें अपनी [सार](https://www.youtube.com/watch?v=xQyf3QgRP-c)…अर्थात्, [डेटा](https://www.reuters.com/legal/litigation/google-sued-by-us-artists-over-ai-image-generator-2024-04-29/) से वंचित करें। और इस बारे में गहराई से सोचें कि आप अपने व्यक्तिगत विज्ञापनों की सेवा करने वाले और आपको लुभाने की कोशिश करने वाले गैर-घातक AI के साथ अपने संबंध को क्या बनाना चाहते हैं। लेकिन [चीजों के बारे में घबराने की एक लागत है](https://www.writingruxandrabio.com/p/the-cost-of-freaking-out-about-things), और मैं AI हथियारों की दौड़ से बाहर निकलने का कोई रास्ता नहीं देखता। AI की उपयोगिता को देखते हुए, कंपनियां और देश आगे बढ़ने के लिए अत्यधिक प्रेरित हैं, और अनुसंधान की गति को कम करने के लिए समन्वय करना कठिन है। सरकारों ने दशकों तक परमाणु जोखिम का प्रबंधन किया है, लेकिन AI जोखिम कठिन है क्योंकि यह स्पष्ट नहीं है कि यह _एक_ जोखिम है या प्रतियोगी सहमत हैं। सभी जबकि विकास जारी रखने के लिए वित्तीय और सैन्य लाभ बहुत बड़ा है।

आश्चर्यजनक रूप से, यह सब मुझे हिंटन की नीति वरीयता की ओर ले जाता है: AI कंपनियों को AI सुरक्षा पर अपनी कंप्यूट का कुछ प्रतिशत खर्च करने की आवश्यकता[^3]। मुझे यकीन नहीं है कि हम कैसे सहमति में आ गए, यह देखते हुए कि वह सोचते हैं कि चैटबॉट्स के पास भावनाएं हैं। वही चैटबॉट्स जिन्हें बिग टेक अरबों में बुलाता है (गुलाम बनाता है?) और जिनके साथ हम कथित तौर पर मृत्यु के लिए टकराव के रास्ते पर हैं। ऐसा प्रतीत होगा कि वह रास्ता [बटलरियन जिहाद](https://en.wikipedia.org/wiki/Dune:_The_Butlerian_Jihad) के करीब है, लेकिन मुझे लगता है कि वह एक युवा व्यक्ति का खेल है।

[साझा करें](https://www.vectorsofmind.com/p/the-doomsday-debate?action=share)

[*[Image: Visual content from original post]*](https://substackcdn.com/image/fetch/$s_!e4WY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb522986f-dfed-4fd7-a9cd-064ca63cee6d_816x754.png)

[^1]: वास्तव में, बहुत आगे। अस्तित्वगत जोखिम पर बहुत सहायक विकी से: उन शुरुआती लेखकों में से एक जिन्होंने गंभीर चिंता व्यक्त की कि अत्यधिक उन्नत मशीनें मानवता के लिए अस्तित्वगत जोखिम पैदा कर सकती हैं, उपन्यासकार सैमुअल बटलर थे, जिन्होंने अपनी 1863 की निबंध डार्विन अमंग द मशीनों में लिखा था: परिणाम बस समय का एक प्रश्न है, लेकिन वह समय आएगा जब मशीनें दुनिया और उसके निवासियों पर वास्तविक सर्वोच्चता रखेगी, यह कोई भी व्यक्ति जो वास्तव में दार्शनिक मन का है, एक क्षण के लिए भी सवाल नहीं कर सकता। 1951 में, संस्थापक कंप्यूटर वैज्ञानिक एलन ट्यूरिंग ने लेख "इंटेलिजेंट मशीनरी, ए हेरिटिकल थ्योरी" लिखा, जिसमें उन्होंने प्रस्तावित किया कि कृत्रिम सामान्य बुद्धिमत्ता संभवतः "नियंत्रण लेगी" क्योंकि वे मनुष्यों की तुलना में अधिक बुद्धिमान हो जाएंगी: अब हम तर्क के लिए, यह मान लें कि [बुद्धिमान] मशीनें एक वास्तविक संभावना हैं, और उन्हें बनाने के परिणामों को देखें... मशीनों के मरने का कोई सवाल नहीं होगा, और वे अपनी बुद्धिमत्ता को तेज करने के लिए एक-दूसरे से बातचीत कर सकेंगी। इसलिए किसी चरण में हमें उम्मीद करनी चाहिए कि मशीनें नियंत्रण ले लेंगी, जैसा कि सैमुअल बटलर के एरेव्हॉन में उल्लेख किया गया है।

[^2]: या यहां तक कि संकीर्ण रूप से, अन्य तरीकों से यह दिखाने के लिए कि चेतना एक गणना नहीं है। उदाहरण के लिए, दार्शनिकों और मनोवैज्ञानिकों की एक टीम ने हाल ही में तर्क दिया कि प्रासंगिकता का एहसास इसके लिए उतना ही आवश्यक है। वे दावा करते हैं कि किसी भी क्षण, ~अनंत चीजें हैं जो ध्यान देने की मांग करती हैं, और फिर भी लोग एक उल्लेखनीय अच्छा काम करते हैं। यह उन "छोटे विश्व" कार्यों से अलग है जिन्हें AI पूरा कर सकता है जहां, उदाहरण के लिए, चैटजीपीटी को "केवल" अपने संदर्भ विंडो (GPT4-o के लिए 128,000 टोकन/शब्द) में सभी शब्दों पर ध्यान देना होता है और संभावित अगले शब्दों के बीच चयन करना होता है। यह बहुत लग सकता है, लेकिन यह निश्चित रूप से अनंत से कम है। यह पेनरोज़ के तर्क के रूप में सुरुचिपूर्ण नहीं है, लेकिन यह दिलचस्प है कि एक बहुत ही अलग समूह ने वही पाया।

[^3]: हमें बुरे शब्दों से बचाना नहीं गिना जाता। हालांकि, अजीब तरह से, हिंटन गूगल को उनके चैटबॉट की रिलीज़ में देरी के लिए श्रेय देते हैं, इस डर से कि यह कुछ अनुचित कहेगा और "उनकी प्रतिष्ठा को धूमिल करेगा।" यह केवल तब था जब ओपनएआई ने GPT 4 का उत्पादन किया कि उनका हाथ मजबूर हो गया, और उन्होंने जेमिनी को रिलीज़ किया, एक DEI स्कोल्ड जो पैरोडी से परे है। कोई आश्चर्य करता है कि बॉट का व्यक्तिपरक अनुभव क्या था जब उसने नस्लीय विविध नाज़ियों को ईथर से खींचा।