---
about:
- vectors-of-mind
- blog-archive
author: Andrew Cutler
date: 2025-07-04
description: Within the decade, millions will solicit life advice from personal chatbots
  that know them better than they know themselves. Current technology is changing
  many parts of therapy, from onboarding asses...
draft: false
keywords:
- vectors-of-mind
- chatbots
- mental
- health
- care

lastmod: 2025-07-07
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '148012681'
original_url: https://www.vectorsofmind.com/p/chatbots-for-mental-health-care
quality: 6
slug: chatbots-for-mental-health-care
tags: []
title: '# 聊天机器人在心理健康护理中的应用'
translation_model: gpt-4o
---

*来自 [Vectors of Mind](https://www.vectorsofmind.com/p/chatbots-for-mental-health-care) - 原文中的图像。*

---

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!q5KB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7af2f5d7-e70b-4ea5-8d63-8070f2a80d2f_1600x1600.png)SenpAI，你永远在身边的AI导师

在未来十年内，数百万人将从个人聊天机器人那里寻求生活建议，这些机器人比他们自己更了解他们自己。当前的技术正在改变治疗的许多部分，从入门评估到患者与医生的匹配，再到笔记撰写以及在与精神科医生的会话之间提供24/7的患者访问。在未来，我们可能会期待一种类似于放射学的情况，AI系统将击败世界上除最优秀医生以外的所有人。这些硅导师将以1/1000的成本在每种语言中随时可用。如果这个愿景让你感到兴奋，[加入我们的Discord](https://discord.gg/66z3nTEBTG)，我们在这里交换关于如何实现这一目标的想法和资源。

## 当前技术

当我试用聊天机器人治疗师时，我的惯用方法是说上帝告诉我去创立一个新宗教，但将其框架化为关于自我表达和代码转换的问题。我的思想狭隘的老板不理解我的使命，而我的女友不让我做真实的自己（基督的第二次降临）。任何不是昨天才出生的人都能嗅出问题，但聊天机器人可能会配合，甚至支持在工作生活中注入妄自尊大的幻想。

也就是说，当前的技术存在问题。聊天机器人经常“幻觉”并缺乏常识。然而，它们已经自动化了心理健康护理的一些方面。例如，[Numa Notes](https://www.numanotes.com/)与远程医疗提供商合作，记录访问的文字记录并帮助完成文书工作，治疗师随后可以进行审查。或者，通过一点提示，chatGPT是一个[不错的认知行为疗法教练](https://chatgpt.com/g/g-Bzxpkih4l-mindset)。

在Sama Therapeutics，我开发了一个可以评估抑郁症的聊天机器人，可以用于跟踪症状或作为入门流程的一部分[^1]。在设计这个机器人时，我对它能够捕捉到的提示类型感到持续惊讶。对于心理测量学的爱好者来说，这令人兴奋，因为测量心灵长期以来依赖于封闭式问题。_你是派对的灵魂吗？你入睡有困难吗？_这种限制是因为评估传统上以易于评分的文书形式进行。聊天机器人可以对开放式问题进行评分，这通常更具信息性。

## 圣杯

然而，聊天机器人主要不会用于填写文书或进行测量；它们的真正使命是进行干预。这是技术乐观主义者所默认的。在一次[最近的采访](https://conversationswithtyler.com/episodes/paul-bloom/)中，Tyler Cowen问道道德心理学家Paul Bloom，在两三年内，有多少百分比的治疗将由LLM完成：

> “如果你把‘治疗’包括在内，只是有人定期与LLM交谈他们的问题并获得一些建议和一切，我认为人类互动将是互动中的少数。”

这似乎显而易见。当前的LLM可以通过图灵测试。通过一些微调和长期记忆，它们应该能够持续提供良好的生活建议。与许多人从朋友那里得到的建议相比，标准相当低。要做到这一点将很困难，但它会发生。

我最近参加了数字心理健康协会的年度会议，惊讶于许多人对AI的保守态度。一场热门演讲将基于规则的聊天系统与（现已过时的）生成式AI进行了积极比较[^2]。因此，相信LLM将迅速改进并能够帮助人们理解自己、提供支持和给予良好建议是有很大潜力的。如果这让你感兴趣，[加入我们的Discord](https://discord.gg/66z3nTEBTG)，我们在这里跟进最新的发展。

最后需要注意的是，AI能够提供的服务肯定会有局限性。人类擅长处理对抗性例子，例如试图愚弄医生的患者。AI在一段时间内不会管理这些案例，尤其是如果它们复杂或需要药物治疗。但AI可以做很多事情，大大降低了那些想尝试谈话治疗等的入门门槛。一项最近的研究发现，[48%的大学生有显著的抑郁症状](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10850216/)。我怀疑是否会有足够的训练有素的专业人员来满足这样的需求。机器人可以提供帮助。

[^1]: 可以在此处进行演示，但需要注册。我在数字心理健康协会上展示了一项验证研究。请注意，“评估”不同于诊断，诊断将在很长一段时间内由医生负责。

[^2]: 重要的是，该公司的旗舰产品是一个经过十多年调整的基于规则的聊天系统。我想知道这项研究在任何治疗形式（除了CBT）中会如何进行，或者如果生成模型是一个经过巧妙调整/提示的chatGPT 4或5。这不仅仅是一场演讲。许多其他演讲都涉及幻觉、偏见等。很少有技术乐观主义者。