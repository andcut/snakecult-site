---
about:
- vectors-of-mind
- blog-archive
author: Andrew Cutler
date: 2025-07-04
description: One of the topics with the worst signal-to-noise ratio is the prospect
  of AI doom. It requires reasoning under uncertainty about intelligence, linear algebra,
  politics, consciousness, and morality—mos...
draft: false
keywords:
- vectors-of-mind
- doomsday
- debate

lastmod: 2025-07-07
license: https://creativecommons.org/licenses/by-sa/4.0/
original_id: '145682175'
original_url: https://www.vectorsofmind.com/p/the-doomsday-debate
quality: 6
slug: the-doomsday-debate
tags: []
title: '# 世界末日辩论'
translation_model: gpt-4o
---

*来自[心灵向量](https://www.vectorsofmind.com/p/the-doomsday-debate) - 原文中的图像。*

---

关于AI末日的前景是信噪比最差的话题之一。它需要在不确定性下进行推理，涉及智能、线性代数、政治、意识和道德——大多数讨论都发生在Twitter/X上。没有人知道答案，但我希望能为这一话题的讨论增添一些价值。在深入探讨之前，请允许我给出一些您应该信任我的理由。

1. 我了解技术方面。我的论文是关于大型语言模型（LLMs）的。

2. 我了解智能，因为我曾在心理测量学领域工作过，包括智力测试。（实际上是阿尔茨海默症和脑震荡测试，这两者高度相关。）

3. 在这个博客上，我广泛撰写了关于[人类水平通用智能的演变](https://www.vectorsofmind.com/p/deja-you-the-recursive-construction)（我从一开始就将其与[人工智能](https://www.vectorsofmind.com/p/the-ai-basis-of-the-eve-theory-of)和[心理测量学](https://www.vectorsofmind.com/p/consequences-of-conscience)联系起来）。

尽管如此，我对AI（以及意识）的信念仍然相当开放，因此不要对我在这里所说的任何事情抱有成见。此外，对于那些更喜欢音频的人，已经为这篇文章进行了旁白。如果您喜欢，可以考虑在[Patreon](https://www.patreon.com/AskwhoCastsAI?)上请他们喝杯咖啡。

[*[图像：原文中的视觉内容]*Askwho Casts AI The Doomsday Debate - By Andrew CutlerAI Narration of The Doomsday Debate - By Andrew Cutler… Listen nowa year ago · 1 like · Askwho Casts AI](https://askwhocastsai.substack.com/p/the-doomsday-debate-by-andrew-cutler?utm_source=substack&utm_campaign=post_embed&utm_medium=web)

## 21世纪的弗兰肯斯坦

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!dgza!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03ba7b69-bae6-4539-b527-7598daba7116_1024x1024.png)MidJourney提示：“有吸引力的弗兰肯斯坦AI助手问‘我能帮您什么？’”这就是我所要求的吗？不。这是我所需要的吗？是的！

严格来说，弗兰肯斯坦是科学家，而不是他创造的生命体。对于AI，其教父是Geoffrey Hinton，他因对神经网络的贡献与Yoshua Bengio和Yann LeCun共同获得了2018年图灵奖，这种架构支撑了当前的AI热潮。今年，他[将LeCun决定开源Meta的语言模型比作开源核武器](https://x.com/ygrowthco/status/1782493076373885336?t=LQtzFlTZQuFZO6Ij3t_Q3Q&s=19)，并认为[聊天机器人具有主观体验](https://x.com/tsarnick/status/1778529076481081833)。他对自己毕生工作的转变的关键在于，AI的能力已经超出了他最狂野的想象，他认为人类的能动性和感质只是烟幕。如果你将智能等同于任务技能（例如生成图像、驾驶汽车），并将十年前的AI能力与现在相比，那么很明显，AI将在十年内比我们更聪明。很少有不如其主人的实体统治其主人的情况；因此，他毕生的工作可能会反过来对付我们。现代的弗兰肯斯坦博士：Geoffrey Hinton。

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!OVE7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc81ae739-94e7-47cc-9a2a-730e4ba08545_850x345.png)[由于自监督生成AI方法的进步，合成面部生成的进展](https://www.researchgate.net/figure/Progress-in-synthetic-face-generation-due-to-advances-in-self-supervised-generative-AI_fig1_352818793)

在[由Elon Musk转发的采访中](https://x.com/elonmusk/status/1801976488251814048)，Hinton给出了未来二十年甚至[几年](https://x.com/OfeliaLamensky/status/1801978585797800365)内人类是否会掌控局面的50/50几率。后来，他指出他尊重的人更有希望，所以情况可能没有那么严峻，“我认为我们有超过一半的机会能活下来。但这并不像AI接管的几率只有1%。这远比那大。”鉴于我们的困境，Hinton偏好的干预措施出人意料地平淡：政府应要求AI公司将其计算资源的20-30%用于安全研究。也许他在故作神秘？如果有人认为[Llama 3](https://en.wikipedia.org/wiki/Llama_\(language_model\))是武器级线性代数，其后代可能很快会终结人类，为何要提前以温和的方式进行打击？邮件投递受到的监管更多。

## AI末日论者

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!hr4e!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d608a6b-8c55-41c1-9bb1-cad96a4be8fe_1600x1159.png)

末日论者是对那些

1. 认为机器人接管的几率比你高的人，或

2. 过于认真对待他们的预测，影响氛围的人。

“未对齐”AI的典型例子是一个递归改进的助手，其任务是生产回形针。它在工作中变得如此出色，以至于最终将地球上的所有金属——包括你血液中的铁——都转化为回形针。这种情况不需要自我导向。最终任务仍然是人类定义的；只是机器人开发了不幸涉及你血液的子任务。其他情景则是机器人“觉醒”成为像人类一样自我导向。一个从不睡觉、读过每一篇科学论文、可以入侵世界上任何手机、对敲诈或[种族灭绝](https://en.wikipedia.org/wiki/Xenocide)毫无顾忌的人类。这样的想法至少可以追溯到1968年斯坦利·库布里克的《太空漫游》：“对不起，戴夫。我恐怕不能那样做。”

2000年，即《太空漫游》设定的前一年，Eliezer Yudkowsky创立了奇点人工智能研究所（后来更名为机器智能研究所，MIRI）。自那时起，他和其他[理性主义者](https://www.lesswrong.com/tag/rationalist-movement)一直认为AI很可能在我们有生之年接管。在过去十年中，技术赶上了。他的论点进入了[主流](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html)，例如出现在[《时代》杂志](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/)上。它们被AI研究人员、斯蒂芬·霍金、埃隆·马斯克，甚至[教皇](https://x.com/AISafetyMemes/status/1735325630089032018)所采纳（或独立推理得出）：

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!SIJ1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb935e8f2-c1d3-4f47-b84e-831f0d4f2412_1374x1498.png)

对于一个通过写[哈利·波特同人小说](https://en.wikipedia.org/wiki/Harry_Potter_and_the_Methods_of_Rationality)磨练自己的人来说，这并不算差。Yudkowski和他的团队一直很高产，他们的论点散布在互联网上。赶上的最好方法是的播客，其中有最近与[Yudkowsky](https://www.dwarkeshpatel.com/p/eliezer-yudkowsky)和前OpenAI安全研究员Leopold Aschenbrenner的4.5小时的节目。大多数论点归结为将比我们更聪明的东西放在盒子里是困难的。尤其是考虑到如果它真的从盒子里出来，它可以潜伏，积累力量。一些末日论者认为这是不可避免的，因为生产（有代理性的）人工智能是如此有用。你信任一个好的助手来掌控你的生活，而世界上最大的公司正在投入资源来打造这样的助手。

一旦你接受人类正在召唤一个硅基神，未来就是你自己价值观的投射。也许神是善良的，它将带来乌托邦。也许[神是钟表匠](https://en.wikipedia.org/wiki/Watchmaker_analogy)，对人类事务不太关心，我们将像蚂蚁在全新世中生活一样继续下去。也许神看到工厂化养殖，[听莫里西的歌](https://www.youtube.com/watch?v=eviyEJRZX30)，决定减少80亿人类更为可持续。或者也许我们召唤了一个[时间旅行的折磨者](https://en.wikipedia.org/wiki/Roko%27s_basilisk)，对那些没有尽力将其带入存在的人进行报复。[马斯克通过开玩笑认识了Grimes](https://www.vice.com/en/article/evkgvz/what-is-rokos-basilisk-elon-musk-grimes)。

## AI反末日论者

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!Yw8P!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb5821c3-3f38-4235-a4d5-2615350d24c2_1232x928.png)提示：“Yann LeCun牵着弗兰肯斯坦。”这是我想要的吗？不。这是我需要的吗？也不。

在1990年代和2000年代初，NIPS，顶级AI会议，是一个温馨的活动，通常在滑雪场附近举办，以便百余名与会者可以在滑雪时交流技术。据我所知，Yann LeCun是个有些古怪的人，几十年来一直在质疑演讲者为何在这个或那个实验中没有考虑神经网络。他是一位杰出的科学家，早在计算能力赶上他的愿景之前就看到了它们的潜力。为此，他现在领导Meta AI。展望未来，他的图灵奖同伴认为AI可能会终结我们（Hinton认为有50%的几率，[Bengio认为有20%的几率](https://blog.biocomm.ai/2024/03/05/pdoom-of-20-yoshua-bengio-a-godfather-of-ai-puts-his-pdoom-at-20/)），这在LeCun看来是荒谬的。

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!BmuA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007d9d8f-61c6-4f9f-9fd7-14ff7e59af8c_584x172.png)

他将AI视为一种工具，没有路径使其成为其他任何东西。Francois Chollet是另一位著名的AI研究员，他对我们即将灭绝的说法泼了冷水。在[Dwarkesh的播客](https://youtu.be/UakqL6Pj9xo?si=Bscnt4Anr_bWEIHp)中，他解释说，许多人混淆了技能和智能，这两者本质上是不同的。对他来说，说一个能在考试中回答问题的机器人和一个青少年一样“聪明”是个不合逻辑的推论。当人类参加考试或在世界中导航时，他们正在做完全不同的事情。当前的AI不如一个孩子甚至一只老鼠聪明。它们不在计分板上，因为它们完全缺乏“[系统2](https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking)”思维。或者，正如LeCun对大型语言模型（LLMs）所说：

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!Z0uf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8381c9d-c385-44b3-b78c-596f2cc69503_584x263.png)

在采访中，Dwarkesh很好地认识到了AI末日论者和渐进主义者之间的这一共识点。所有各方都认为某种元认知系统是必要的，但在生产难度上存在分歧。

## 我的观点

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!ojLt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c4ad753-707a-4887-85ab-f66691b5b711_678x1200.png)规则33：如果它存在，就会有[令人难以置信的好同人艺术。](https://www.reddit.com/r/universalpaperclips/comments/123msul/if_is_follows_ought_itll_do_what_they_thought/)

在这场辩论中，大多数人假设能动性是一种计算——我们的自由意志感和计划能力是我们大脑中运行的程序的结果。因此，如果我必须最大程度地改变这个群体的观点，我会给他们一本Roger Penrose的《[心灵的阴影](https://en.wikipedia.org/wiki/Shadows_of_the_Mind)》和5克蘑菇：对还原主义的老派夹击。

Penrose因其在黑洞方面的工作获得了诺贝尔物理学奖。在《心灵的阴影》中，他认为大脑中的量子坍缩产生了意识，这无法被任何计算机模拟。与麻醉师[Stuart Hameroff](https://x.com/StuartHameroff)合作，他提出这发生在大脑的微管中，这些微管在神经元周围形成支架。如果你大声说出来会更有意义：“大脑在微管中存储量子。”

这就是蘑菇的作用。要吞下这样一颗药丸，需要放弃任何认为意识是平凡的或你理解它的感觉。物理学家通常可以在清醒时做到这一点；其他人则需要一些真菌的勇气。作为一名物理学家，Penrose的论点主要是数学上的。他解释了哥德尔的不完备定理，表明AI永远无法做到某些数学证明，因为它们是机器人，纯粹是计算性的。鉴于人类没有这种限制，他认为人类认知因此不是一种计算。从那里，他推断生物学的特殊调料必须与量子坍缩有关，这是在自然界中找到非计算现象的最佳地点。这有可能解决物理学中的其他谜题，例如薛定谔的猫。我没有做到公正。你应该读这本书，或者在20分钟的预算内，[听他的讲述](https://youtu.be/hXgqik6HXc0?si=oafnrwSvfYS-u9Kw)。

还有许多其他方法可以得出机器意识不太可能，或者至少目前我们无法预测[^2]。我提到Penrose是为了展示AI时间表如何碰到关于智能、能动性和宇宙本质的未解之谜。即使在相对平凡的心理测量学领域，智力的定义也存在很大争议，[以及它与智商的关系](https://www.vectorsofmind.com/i/130101130/the-general-factor-of-intelligence)。我们甚至不知道技能和智力在人类中是如何对应的。这是在涉及自由意志和统一物理学理论的问题之前，Penrose建议这将从量子意识的解释中得出。

尽管如此，如果我必须给AI作为生存风险的几率下注，大约是10%。即使意识只是计算，我同意LeCun和Chollet的观点，元认知是困难的部分，“硬起飞”不太可能。也就是说，会有真正智能出现的迹象，我们将能够对此作出反应。

此外，即使召唤出一个硅基神，我也认为神是善良的或不关心我们的几率相当高。后者可能是灾难性的，但严格来说可能不是生存风险。蚂蚁在我们修建高速公路时日子不好过，但它们仍然能生存。

10%接近于俄罗斯轮盘赌，这不算是好消息。这使我处于[AGI警惕](https://x.com/robbensinger/status/1801306833325592759)阵营。那么我们应该怎么做呢？好吧，[匿名戒酒会几十年前就解决了这个问题](https://en.wikipedia.org/wiki/Serenity_Prayer)：

_上帝，请赐予我宁静，接受我无法改变的事情，_

_勇气去改变我能改变的事情，_

_以及分辨两者的智慧。_

实际上，我们正在随波逐流。这并不适用于每个人。有些人可以从事公共政策或AI安全工作。如果可以，请捐赠。拒绝他们你的[精华](https://www.youtube.com/watch?v=xQyf3QgRP-c)…呃，[数据](https://www.reuters.com/legal/litigation/google-sued-by-us-artists-over-ai-image-generator-2024-04-29/)。并深入思考你希望与非致命AI的关系，它们提供个性化广告并试图诱惑你。但[恐慌的代价](https://www.writingruxandrabio.com/p/the-cost-of-freaking-out-about-things)是存在的，我看不出AI军备竞赛的出路。鉴于AI的实用性，公司和国家有很高的动机继续推进，很难协调减缓研究速度。政府已经管理核风险数十年，但AI风险更难，因为不清楚它是否_是_风险，或者竞争对手是否同意。同时，继续发展的财务和军事收益巨大。

令人惊讶的是，所有这些都让我倾向于Hinton的政策偏好：要求AI公司将其计算的一部分用于AI安全[^3]。我不确定我们是如何达成一致的，鉴于他认为聊天机器人有感情。那些大科技公司召唤（奴役？）的聊天机器人，据说我们正与其在死亡的碰撞路线上。似乎那条路更接近于[巴特勒圣战](https://en.wikipedia.org/wiki/Dune:_The_Butlerian_Jihad)，但我想那是年轻人的游戏。

[分享](https://www.vectorsofmind.com/p/the-doomsday-debate?utm_source=substack&utm_medium=email&utm_content=share&action=share)

[*[图像：原文中的视觉内容]*](https://substackcdn.com/image/fetch/$s_!e4WY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb522986f-dfed-4fd7-a9cd-064ca63cee6d_816x754.png)

[^1]: 实际上，更早。来自关于生存风险的非常有用的维基：最早表达对高度先进机器可能对人类构成生存风险的严重担忧的作者之一是小说家Samuel Butler，他在1863年的文章《机器中的达尔文》中写道：结果只是时间问题，但时间将会到来，机器将拥有对世界及其居民的真正统治权，这是任何真正哲学头脑的人都无法质疑的。在1951年，基础计算机科学家艾伦·图灵在文章《智能机器，一个异端理论》中提出，人工通用智能可能会随着它们变得比人类更聪明而“控制”世界：现在让我们假设，为了论证的目的，[智能]机器是真实的可能性，并看看构建它们的后果……机器不会死亡，它们能够互相交流以提高智慧。因此，在某个阶段，我们应该预期机器会以Samuel Butler在《埃瑞温》中提到的方式控制。

[^2]: 或者即使是狭义的，其他方法来证明意识不是一种计算。例如，一组哲学家和心理学家最近论证说，相关性实现需要如此。他们声称，在任何时刻，都有~无限的事情需要注意，而人们却做得非常好。这与AI可以完成的“小世界”任务不同，例如chatGPT“只”需要关注其上下文窗口中的所有单词（GPT4-o为128,000个标记/单词），并在数万个可能的下一个单词之间进行选择。看起来可能很多，但肯定比无限少。这不如Penrose的论点优雅，但有趣的是，一个非常不同的群体发现了同样的事情。

[^3]: 拯救我们免于坏话不算。然而，奇怪的是，Hinton称赞谷歌因为担心他们的聊天机器人会说出不当言论而“玷污他们的声誉”而推迟发布。只有在OpenAI推出GPT 4后，他们才被迫发布Gemini，一个超越讽刺的DEI责备者。人们不禁想知道，当机器人从虚无中拉出种族多样化的纳粹时，它的主观体验是什么。