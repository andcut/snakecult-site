---
title: "Lexical Analysis Vs Bias"
date: "2025-07-04"
lastmod: "2025-07-04"
slug: "lexical-analysis-vs-bias"
description: "[JL Austin quote]"
keywords:
  - "vectors-of-mind"
  - "lexical"
  - "analysis"
  - "bias"
about: ['vectors-of-mind', 'blog-archive']
tags: []
author: "Andrew Cutler"
license: "https://creativecommons.org/licenses/by-sa/4.0/"
draft: True
quality: 1
original_id: "61387112"
original_url: "https://www.vectorsofmind.com/p/lexical-analysis-vs-bias"
---
*From [Vectors of Mind](https://www.vectorsofmind.com/p/lexical-analysis-vs-bias) - images at original.*

---

[JL Austin quote]

Under the lexical analysis view, the job of a researcher is to read off data from structure implied by language. This can show things such as the number of dimensions required to represent personality. That’s not at all obvious just from thinking about how one has seen language used, it’s quite subtle. One of the main arguments in this blog is that language data is informative to more than gross structure. [reference altruism and gender posts. Highly accurate. Extracts much more truth than typical methods using subjects and surveys.] (We could have been doing so for a long time, datasets from the 90s could have resolved the question of altruism better than Ashton paper. However, now we can do so using many order or magnitude more data.) 

Which brings us to the field of NLP. For ML research to be published it must include an impact statement, which is some copypasta about harmful stereotypes and truthfulness. This area of research is high on moralizing, low on standards. Reference that the GPT 4chan scored highest on the truthfulness benchmark. Men and white people usually treated worst by models, despite hand-wringing about ‘marginalized groups’. 
